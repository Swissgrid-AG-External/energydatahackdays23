{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111ab25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: plotly in /home/jupyter-user02/.local/lib/python3.9/site-packages (5.17.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/jupyter-user02/.local/lib/python3.9/site-packages (from plotly) (8.2.3)\n",
      "Requirement already satisfied: packaging in /opt/tljh/user/lib/python3.9/site-packages (from plotly) (23.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a284d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import plotly as ply\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bd20ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_losses_df = pd.read_csv(\n",
    "    \"../data/Avtice-losses.csv\", skiprows=2, names=[\"datetime\", \"MWh\"], parse_dates=[\"datetime\"], index_col=\"datetime\")\n",
    "\n",
    "active_losses_df.index = active_losses_df.tz_localize('Europe/Brussels', ambiguous=\"infer\").tz_convert('UTC').index\n",
    "active_losses_df.index = active_losses_df.index - pd.Timedelta(minutes=15)\n",
    "active_losses_df = active_losses_df.resample('1H').sum()\n",
    "active_losses_df[\"MWh\"] = active_losses_df[\"MWh\"]/1000\n",
    "\n",
    "\n",
    "df = active_losses_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092c407f",
   "metadata": {},
   "source": [
    "# Predict next hour based on last 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1010679a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['MWh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6715e0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_143381/2628811236.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['month'] = (df.index.month).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Create lagged features\n",
    "for col in feature_columns:\n",
    "    for i in range(1, 7 * 24 + 1):  # for past 7 days (in hours)\n",
    "        df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
    "df['month'] = (df.index.month).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c883cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWh</th>\n",
       "      <th>lag_MWh_1</th>\n",
       "      <th>lag_MWh_2</th>\n",
       "      <th>lag_MWh_3</th>\n",
       "      <th>lag_MWh_4</th>\n",
       "      <th>lag_MWh_5</th>\n",
       "      <th>lag_MWh_6</th>\n",
       "      <th>lag_MWh_7</th>\n",
       "      <th>lag_MWh_8</th>\n",
       "      <th>lag_MWh_9</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_MWh_160</th>\n",
       "      <th>lag_MWh_161</th>\n",
       "      <th>lag_MWh_162</th>\n",
       "      <th>lag_MWh_163</th>\n",
       "      <th>lag_MWh_164</th>\n",
       "      <th>lag_MWh_165</th>\n",
       "      <th>lag_MWh_166</th>\n",
       "      <th>lag_MWh_167</th>\n",
       "      <th>lag_MWh_168</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+00:00</th>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>135.133852</td>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>131.699424</td>\n",
       "      <td>135.133852</td>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 18:00:00+00:00</th>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>149.349078</td>\n",
       "      <td>...</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>103.315829</td>\n",
       "      <td>99.421761</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00+00:00</th>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>...</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>103.315829</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00+00:00</th>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>...</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00+00:00</th>\n",
       "      <td>171.370277</td>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>...</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00+00:00</th>\n",
       "      <td>146.054791</td>\n",
       "      <td>171.370277</td>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>...</td>\n",
       "      <td>136.717219</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows Ã— 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MWh   lag_MWh_1   lag_MWh_2   lag_MWh_3  \\\n",
       "datetime                                                                    \n",
       "2018-12-31 23:00:00+00:00  139.525004         NaN         NaN         NaN   \n",
       "2019-01-01 00:00:00+00:00  129.716036  139.525004         NaN         NaN   \n",
       "2019-01-01 01:00:00+00:00  133.398074  129.716036  139.525004         NaN   \n",
       "2019-01-01 02:00:00+00:00  135.133852  133.398074  129.716036  139.525004   \n",
       "2019-01-01 03:00:00+00:00  131.699424  135.133852  133.398074  129.716036   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  171.707318  152.159763  162.995636  188.541866   \n",
       "2021-12-31 19:00:00+00:00  159.462903  171.707318  152.159763  162.995636   \n",
       "2021-12-31 20:00:00+00:00  155.109520  159.462903  171.707318  152.159763   \n",
       "2021-12-31 21:00:00+00:00  171.370277  155.109520  159.462903  171.707318   \n",
       "2021-12-31 22:00:00+00:00  146.054791  171.370277  155.109520  159.462903   \n",
       "\n",
       "                            lag_MWh_4   lag_MWh_5   lag_MWh_6   lag_MWh_7  \\\n",
       "datetime                                                                    \n",
       "2018-12-31 23:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 00:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 01:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 02:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 03:00:00+00:00  139.525004         NaN         NaN         NaN   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  176.617953  167.343565  145.792085  152.648212   \n",
       "2021-12-31 19:00:00+00:00  188.541866  176.617953  167.343565  145.792085   \n",
       "2021-12-31 20:00:00+00:00  162.995636  188.541866  176.617953  167.343565   \n",
       "2021-12-31 21:00:00+00:00  152.159763  162.995636  188.541866  176.617953   \n",
       "2021-12-31 22:00:00+00:00  171.707318  152.159763  162.995636  188.541866   \n",
       "\n",
       "                            lag_MWh_8   lag_MWh_9  ...  lag_MWh_160  \\\n",
       "datetime                                           ...                \n",
       "2018-12-31 23:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 00:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 01:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 02:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 03:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "...                               ...         ...  ...          ...   \n",
       "2021-12-31 18:00:00+00:00  150.967027  149.349078  ...   119.124221   \n",
       "2021-12-31 19:00:00+00:00  152.648212  150.967027  ...   125.661865   \n",
       "2021-12-31 20:00:00+00:00  145.792085  152.648212  ...   136.132174   \n",
       "2021-12-31 21:00:00+00:00  167.343565  145.792085  ...   144.984402   \n",
       "2021-12-31 22:00:00+00:00  176.617953  167.343565  ...   136.717219   \n",
       "\n",
       "                           lag_MWh_161  lag_MWh_162  lag_MWh_163  lag_MWh_164  \\\n",
       "datetime                                                                        \n",
       "2018-12-31 23:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00   115.795738   103.814345    97.836516    97.016161   \n",
       "2021-12-31 19:00:00+00:00   119.124221   115.795738   103.814345    97.836516   \n",
       "2021-12-31 20:00:00+00:00   125.661865   119.124221   115.795738   103.814345   \n",
       "2021-12-31 21:00:00+00:00   136.132174   125.661865   119.124221   115.795738   \n",
       "2021-12-31 22:00:00+00:00   144.984402   136.132174   125.661865   119.124221   \n",
       "\n",
       "                           lag_MWh_165  lag_MWh_166  lag_MWh_167  lag_MWh_168  \\\n",
       "datetime                                                                        \n",
       "2018-12-31 23:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00   103.763064   105.380492   103.315829    99.421761   \n",
       "2021-12-31 19:00:00+00:00    97.016161   103.763064   105.380492   103.315829   \n",
       "2021-12-31 20:00:00+00:00    97.836516    97.016161   103.763064   105.380492   \n",
       "2021-12-31 21:00:00+00:00   103.814345    97.836516    97.016161   103.763064   \n",
       "2021-12-31 22:00:00+00:00   115.795738   103.814345    97.836516    97.016161   \n",
       "\n",
       "                           month  \n",
       "datetime                          \n",
       "2018-12-31 23:00:00+00:00     12  \n",
       "2019-01-01 00:00:00+00:00      1  \n",
       "2019-01-01 01:00:00+00:00      1  \n",
       "2019-01-01 02:00:00+00:00      1  \n",
       "2019-01-01 03:00:00+00:00      1  \n",
       "...                          ...  \n",
       "2021-12-31 18:00:00+00:00     12  \n",
       "2021-12-31 19:00:00+00:00     12  \n",
       "2021-12-31 20:00:00+00:00     12  \n",
       "2021-12-31 21:00:00+00:00     12  \n",
       "2021-12-31 22:00:00+00:00     12  \n",
       "\n",
       "[26304 rows x 170 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71dd3b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26304"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd81e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MWh', axis=1)  # Features\n",
    "y = df['MWh']  # Target variable\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train = X[:21000]\n",
    "y_train = y[:21000]\n",
    "X_test = X[21001:]\n",
    "y_test = y[21001:]\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0708f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 42853\n",
      "[LightGBM] [Info] Number of data points in the train set: 21000, number of used features: 169\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A100 80GB PCIe, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 169 dense feature groups (3.44 MB) transferred to GPU in 0.041687 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 107.649150\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for LightGBM\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'device': 'gpu'  # Enable GPU support\n",
    "}\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "# Train the model\n",
    "model = lgb.train(params, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "147586c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.189550518894444"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "metrics.mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04595a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.768973898822182\n",
      "MAE: 8.189550518894444\n"
     ]
    }
   ],
   "source": [
    "mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e2dd96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f79a6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c192400c",
   "metadata": {},
   "source": [
    "# Using Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with a date index\n",
    "date_index = active_losses_df.index.date\n",
    "new_df = pd.DataFrame(index=date_index)\n",
    "new_df.index = new_df.index.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty array for each date with 24 values\n",
    "new_df['MWh'] = [np.array([np.nan] * 24) for _ in range(len(new_df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75466ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the array with the hourly values\n",
    "for date in new_df.index:\n",
    "    hourly_values = active_losses_df.loc[date.strftime('%Y-%m-%d')]['MWh'].values\n",
    "    new_df.at[date, 'MWh'][:len(hourly_values)] = hourly_values\n",
    "    \n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca551b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6c711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the array with the hourly values\n",
    "for date in date_index:\n",
    "    #hourly_values = active_losses_df.loc[date.strftime('%Y-%m-%d')]['MWh'].values\n",
    "    #new_df.at[date, 'MWh'][:len(hourly_values)] = hourly_values\n",
    "    \n",
    "    date_values = active_losses_df.loc[date.strftime('%Y-%m-%d')]\n",
    "    #print(date_values)\n",
    "    #print(date_values['MWh'].values)\n",
    "    new_df.loc[date] = date_values.values\n",
    "\n",
    "# Optional: Fill NaN values with zeros\n",
    "new_df['MWh'] = new_df['MWh'].apply(lambda x: np.nan_to_num(x, nan=0))\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "#print(new_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63d2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second index that repeats from 1 to 8\n",
    "df['sample_index'] = (df.reset_index().index // 8) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f891ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e44c19e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>solar_fore_de_MW</th>\n",
       "      <th>solar_fore_it_MW</th>\n",
       "      <th>wind_fore_de_MW</th>\n",
       "      <th>wind_fore_it_MW</th>\n",
       "      <th>temperature_fore_ch</th>\n",
       "      <th>temperature_fore_fr</th>\n",
       "      <th>temperature_fore_de</th>\n",
       "      <th>temperature_fore_it</th>\n",
       "      <th>Month_1</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_mwh_3</th>\n",
       "      <th>lag_mwh_4</th>\n",
       "      <th>lag_mwh_5</th>\n",
       "      <th>lag_mwh_6</th>\n",
       "      <th>lag_mwh_7</th>\n",
       "      <th>lag_mwh_8</th>\n",
       "      <th>lag_mwh_9</th>\n",
       "      <th>lag_mwh_10</th>\n",
       "      <th>lag_mwh_11</th>\n",
       "      <th>lag_mwh_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 12:00:00+00:00</td>\n",
       "      <td>2623.0</td>\n",
       "      <td>4722.0</td>\n",
       "      <td>34266.1751</td>\n",
       "      <td>4414.9774</td>\n",
       "      <td>4.882300</td>\n",
       "      <td>8.647100</td>\n",
       "      <td>7.459600</td>\n",
       "      <td>7.738600</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 13:00:00+00:00</td>\n",
       "      <td>1775.0</td>\n",
       "      <td>3595.0</td>\n",
       "      <td>35997.4125</td>\n",
       "      <td>3952.2944</td>\n",
       "      <td>4.808495</td>\n",
       "      <td>8.582632</td>\n",
       "      <td>7.264148</td>\n",
       "      <td>7.570064</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 14:00:00+00:00</td>\n",
       "      <td>722.0</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>37841.5032</td>\n",
       "      <td>3476.5546</td>\n",
       "      <td>4.524808</td>\n",
       "      <td>8.317492</td>\n",
       "      <td>6.936318</td>\n",
       "      <td>7.047034</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 15:00:00+00:00</td>\n",
       "      <td>41.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>37485.1176</td>\n",
       "      <td>3050.5234</td>\n",
       "      <td>4.126172</td>\n",
       "      <td>7.928399</td>\n",
       "      <td>6.524037</td>\n",
       "      <td>6.294940</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 16:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38010.4885</td>\n",
       "      <td>2790.4242</td>\n",
       "      <td>3.707520</td>\n",
       "      <td>7.492072</td>\n",
       "      <td>6.075238</td>\n",
       "      <td>5.439215</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26286</th>\n",
       "      <td>2021-12-31 18:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36997.7200</td>\n",
       "      <td>1108.4000</td>\n",
       "      <td>8.530000</td>\n",
       "      <td>9.960000</td>\n",
       "      <td>10.790000</td>\n",
       "      <td>9.590000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26287</th>\n",
       "      <td>2021-12-31 19:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35666.9300</td>\n",
       "      <td>1077.9700</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>10.630000</td>\n",
       "      <td>9.110000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26288</th>\n",
       "      <td>2021-12-31 20:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34383.8800</td>\n",
       "      <td>1048.2800</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>10.510000</td>\n",
       "      <td>8.670000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26289</th>\n",
       "      <td>2021-12-31 21:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33075.2500</td>\n",
       "      <td>1078.7800</td>\n",
       "      <td>6.970000</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>10.320000</td>\n",
       "      <td>8.140000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26290</th>\n",
       "      <td>2021-12-31 22:00:00+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32350.7300</td>\n",
       "      <td>1188.4300</td>\n",
       "      <td>6.790000</td>\n",
       "      <td>8.220000</td>\n",
       "      <td>10.230000</td>\n",
       "      <td>7.670000</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26291 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        datetime  solar_fore_de_MW  solar_fore_it_MW  \\\n",
       "0      2019-01-01 12:00:00+00:00            2623.0            4722.0   \n",
       "1      2019-01-01 13:00:00+00:00            1775.0            3595.0   \n",
       "2      2019-01-01 14:00:00+00:00             722.0            1965.0   \n",
       "3      2019-01-01 15:00:00+00:00              41.0             343.0   \n",
       "4      2019-01-01 16:00:00+00:00               0.0               0.0   \n",
       "...                          ...               ...               ...   \n",
       "26286  2021-12-31 18:00:00+00:00               0.0               0.0   \n",
       "26287  2021-12-31 19:00:00+00:00               0.0               0.0   \n",
       "26288  2021-12-31 20:00:00+00:00               0.0               0.0   \n",
       "26289  2021-12-31 21:00:00+00:00               0.0               0.0   \n",
       "26290  2021-12-31 22:00:00+00:00               0.0               0.0   \n",
       "\n",
       "       wind_fore_de_MW  wind_fore_it_MW  temperature_fore_ch  \\\n",
       "0           34266.1751        4414.9774             4.882300   \n",
       "1           35997.4125        3952.2944             4.808495   \n",
       "2           37841.5032        3476.5546             4.524808   \n",
       "3           37485.1176        3050.5234             4.126172   \n",
       "4           38010.4885        2790.4242             3.707520   \n",
       "...                ...              ...                  ...   \n",
       "26286       36997.7200        1108.4000             8.530000   \n",
       "26287       35666.9300        1077.9700             8.000000   \n",
       "26288       34383.8800        1048.2800             7.500000   \n",
       "26289       33075.2500        1078.7800             6.970000   \n",
       "26290       32350.7300        1188.4300             6.790000   \n",
       "\n",
       "       temperature_fore_fr  temperature_fore_de  temperature_fore_it  Month_1  \\\n",
       "0                 8.647100             7.459600             7.738600     True   \n",
       "1                 8.582632             7.264148             7.570064     True   \n",
       "2                 8.317492             6.936318             7.047034     True   \n",
       "3                 7.928399             6.524037             6.294940     True   \n",
       "4                 7.492072             6.075238             5.439215     True   \n",
       "...                    ...                  ...                  ...      ...   \n",
       "26286             9.960000            10.790000             9.590000    False   \n",
       "26287             9.400000            10.630000             9.110000    False   \n",
       "26288             8.880000            10.510000             8.670000    False   \n",
       "26289             8.510000            10.320000             8.140000    False   \n",
       "26290             8.220000            10.230000             7.670000    False   \n",
       "\n",
       "       ...  lag_mwh_3  lag_mwh_4  lag_mwh_5  lag_mwh_6  lag_mwh_7  lag_mwh_8  \\\n",
       "0      ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1      ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "2      ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "3      ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "4      ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "...    ...        ...        ...        ...        ...        ...        ...   \n",
       "26286  ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "26287  ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "26288  ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "26289  ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "26290  ...       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "       lag_mwh_9  lag_mwh_10  lag_mwh_11  lag_mwh_12  \n",
       "0           -1.0        -1.0        -1.0        -1.0  \n",
       "1           -1.0        -1.0        -1.0        -1.0  \n",
       "2           -1.0        -1.0        -1.0        -1.0  \n",
       "3           -1.0        -1.0        -1.0        -1.0  \n",
       "4           -1.0        -1.0        -1.0        -1.0  \n",
       "...          ...         ...         ...         ...  \n",
       "26286       -1.0        -1.0        -1.0        -1.0  \n",
       "26287       -1.0        -1.0        -1.0        -1.0  \n",
       "26288       -1.0        -1.0        -1.0        -1.0  \n",
       "26289       -1.0        -1.0        -1.0        -1.0  \n",
       "26290       -1.0        -1.0        -1.0        -1.0  \n",
       "\n",
       "[26291 rows x 66 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv(\"df.csv\")\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bedfcd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'solar_fore_de_MW', 'solar_fore_it_MW', 'wind_fore_de_MW',\n",
       "       'wind_fore_it_MW', 'temperature_fore_ch', 'temperature_fore_fr',\n",
       "       'temperature_fore_de', 'temperature_fore_it', 'Month_1', 'Month_2',\n",
       "       'Month_3', 'Month_4', 'Month_5', 'Month_6', 'Month_7', 'Month_8',\n",
       "       'Month_9', 'Month_10', 'Month_11', 'Month_12', 'Day_0', 'Day_1',\n",
       "       'Day_2', 'Day_3', 'Day_4', 'Day_5', 'Day_6', 'Hour_0', 'Hour_1',\n",
       "       'Hour_2', 'Hour_3', 'Hour_4', 'Hour_5', 'Hour_6', 'Hour_7', 'Hour_8',\n",
       "       'Hour_9', 'Hour_10', 'Hour_11', 'Hour_12', 'Hour_13', 'Hour_14',\n",
       "       'Hour_15', 'Hour_16', 'Hour_17', 'Hour_18', 'Hour_19', 'Hour_20',\n",
       "       'Hour_21', 'Hour_22', 'Hour_23', 'target', 'std_mwh', 'lag_mwh_1',\n",
       "       'lag_mwh_2', 'lag_mwh_3', 'lag_mwh_4', 'lag_mwh_5', 'lag_mwh_6',\n",
       "       'lag_mwh_7', 'lag_mwh_8', 'lag_mwh_9', 'lag_mwh_10', 'lag_mwh_11',\n",
       "       'lag_mwh_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
