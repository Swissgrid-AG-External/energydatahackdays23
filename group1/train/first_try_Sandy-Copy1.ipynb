{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a284d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd20ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+00:00</th>\n",
       "      <td>139.525004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>129.716036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>133.398074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>135.133852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>131.699424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 18:00:00+00:00</th>\n",
       "      <td>171.707318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00+00:00</th>\n",
       "      <td>159.462903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00+00:00</th>\n",
       "      <td>155.109520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00+00:00</th>\n",
       "      <td>171.370277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00+00:00</th>\n",
       "      <td>146.054791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MWh\n",
       "datetime                             \n",
       "2018-12-31 23:00:00+00:00  139.525004\n",
       "2019-01-01 00:00:00+00:00  129.716036\n",
       "2019-01-01 01:00:00+00:00  133.398074\n",
       "2019-01-01 02:00:00+00:00  135.133852\n",
       "2019-01-01 03:00:00+00:00  131.699424\n",
       "...                               ...\n",
       "2021-12-31 18:00:00+00:00  171.707318\n",
       "2021-12-31 19:00:00+00:00  159.462903\n",
       "2021-12-31 20:00:00+00:00  155.109520\n",
       "2021-12-31 21:00:00+00:00  171.370277\n",
       "2021-12-31 22:00:00+00:00  146.054791\n",
       "\n",
       "[26304 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_losses_df = pd.read_csv(\n",
    "    \"../data/Avtice-losses.csv\", skiprows=2, names=[\"datetime\", \"MWh\"], parse_dates=[\"datetime\"], index_col=\"datetime\")\n",
    "\n",
    "active_losses_df.index = active_losses_df.tz_localize('Europe/Brussels', ambiguous=\"infer\").tz_convert('UTC').index\n",
    "active_losses_df.index = active_losses_df.index - pd.Timedelta(minutes=15)\n",
    "active_losses_df = active_losses_df.resample('1H').sum()\n",
    "active_losses_df[\"MWh\"] = active_losses_df[\"MWh\"]/1000\n",
    "active_losses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5186e",
   "metadata": {},
   "source": [
    "# Predict next hour based on last 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b1a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = active_losses_df.copy()\n",
    "feature_columns = ['MWh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a48519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_74458/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n"
     ]
    }
   ],
   "source": [
    "# Create lagged features\n",
    "for col in feature_columns:\n",
    "    for i in range(1, 7 * 24 + 1):  # for past 7 days (in hours)\n",
    "        df1[f'lag_{col}_{i}'] = df1[col].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f464105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWh</th>\n",
       "      <th>lag_MWh_1</th>\n",
       "      <th>lag_MWh_2</th>\n",
       "      <th>lag_MWh_3</th>\n",
       "      <th>lag_MWh_4</th>\n",
       "      <th>lag_MWh_5</th>\n",
       "      <th>lag_MWh_6</th>\n",
       "      <th>lag_MWh_7</th>\n",
       "      <th>lag_MWh_8</th>\n",
       "      <th>lag_MWh_9</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_MWh_159</th>\n",
       "      <th>lag_MWh_160</th>\n",
       "      <th>lag_MWh_161</th>\n",
       "      <th>lag_MWh_162</th>\n",
       "      <th>lag_MWh_163</th>\n",
       "      <th>lag_MWh_164</th>\n",
       "      <th>lag_MWh_165</th>\n",
       "      <th>lag_MWh_166</th>\n",
       "      <th>lag_MWh_167</th>\n",
       "      <th>lag_MWh_168</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+00:00</th>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>135.133852</td>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>131.699424</td>\n",
       "      <td>135.133852</td>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 18:00:00+00:00</th>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>149.349078</td>\n",
       "      <td>...</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>103.315829</td>\n",
       "      <td>99.421761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00+00:00</th>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>...</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>103.315829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00+00:00</th>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>...</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00+00:00</th>\n",
       "      <td>171.370277</td>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>...</td>\n",
       "      <td>136.717219</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00+00:00</th>\n",
       "      <td>146.054791</td>\n",
       "      <td>171.370277</td>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>...</td>\n",
       "      <td>136.431471</td>\n",
       "      <td>136.717219</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MWh   lag_MWh_1   lag_MWh_2   lag_MWh_3  \\\n",
       "datetime                                                                    \n",
       "2018-12-31 23:00:00+00:00  139.525004         NaN         NaN         NaN   \n",
       "2019-01-01 00:00:00+00:00  129.716036  139.525004         NaN         NaN   \n",
       "2019-01-01 01:00:00+00:00  133.398074  129.716036  139.525004         NaN   \n",
       "2019-01-01 02:00:00+00:00  135.133852  133.398074  129.716036  139.525004   \n",
       "2019-01-01 03:00:00+00:00  131.699424  135.133852  133.398074  129.716036   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  171.707318  152.159763  162.995636  188.541866   \n",
       "2021-12-31 19:00:00+00:00  159.462903  171.707318  152.159763  162.995636   \n",
       "2021-12-31 20:00:00+00:00  155.109520  159.462903  171.707318  152.159763   \n",
       "2021-12-31 21:00:00+00:00  171.370277  155.109520  159.462903  171.707318   \n",
       "2021-12-31 22:00:00+00:00  146.054791  171.370277  155.109520  159.462903   \n",
       "\n",
       "                            lag_MWh_4   lag_MWh_5   lag_MWh_6   lag_MWh_7  \\\n",
       "datetime                                                                    \n",
       "2018-12-31 23:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 00:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 01:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 02:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 03:00:00+00:00  139.525004         NaN         NaN         NaN   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  176.617953  167.343565  145.792085  152.648212   \n",
       "2021-12-31 19:00:00+00:00  188.541866  176.617953  167.343565  145.792085   \n",
       "2021-12-31 20:00:00+00:00  162.995636  188.541866  176.617953  167.343565   \n",
       "2021-12-31 21:00:00+00:00  152.159763  162.995636  188.541866  176.617953   \n",
       "2021-12-31 22:00:00+00:00  171.707318  152.159763  162.995636  188.541866   \n",
       "\n",
       "                            lag_MWh_8   lag_MWh_9  ...  lag_MWh_159  \\\n",
       "datetime                                           ...                \n",
       "2018-12-31 23:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 00:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 01:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 02:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 03:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "...                               ...         ...  ...          ...   \n",
       "2021-12-31 18:00:00+00:00  150.967027  149.349078  ...   125.661865   \n",
       "2021-12-31 19:00:00+00:00  152.648212  150.967027  ...   136.132174   \n",
       "2021-12-31 20:00:00+00:00  145.792085  152.648212  ...   144.984402   \n",
       "2021-12-31 21:00:00+00:00  167.343565  145.792085  ...   136.717219   \n",
       "2021-12-31 22:00:00+00:00  176.617953  167.343565  ...   136.431471   \n",
       "\n",
       "                           lag_MWh_160  lag_MWh_161  lag_MWh_162  lag_MWh_163  \\\n",
       "datetime                                                                        \n",
       "2018-12-31 23:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00   119.124221   115.795738   103.814345    97.836516   \n",
       "2021-12-31 19:00:00+00:00   125.661865   119.124221   115.795738   103.814345   \n",
       "2021-12-31 20:00:00+00:00   136.132174   125.661865   119.124221   115.795738   \n",
       "2021-12-31 21:00:00+00:00   144.984402   136.132174   125.661865   119.124221   \n",
       "2021-12-31 22:00:00+00:00   136.717219   144.984402   136.132174   125.661865   \n",
       "\n",
       "                           lag_MWh_164  lag_MWh_165  lag_MWh_166  lag_MWh_167  \\\n",
       "datetime                                                                        \n",
       "2018-12-31 23:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00    97.016161   103.763064   105.380492   103.315829   \n",
       "2021-12-31 19:00:00+00:00    97.836516    97.016161   103.763064   105.380492   \n",
       "2021-12-31 20:00:00+00:00   103.814345    97.836516    97.016161   103.763064   \n",
       "2021-12-31 21:00:00+00:00   115.795738   103.814345    97.836516    97.016161   \n",
       "2021-12-31 22:00:00+00:00   119.124221   115.795738   103.814345    97.836516   \n",
       "\n",
       "                           lag_MWh_168  \n",
       "datetime                                \n",
       "2018-12-31 23:00:00+00:00          NaN  \n",
       "2019-01-01 00:00:00+00:00          NaN  \n",
       "2019-01-01 01:00:00+00:00          NaN  \n",
       "2019-01-01 02:00:00+00:00          NaN  \n",
       "2019-01-01 03:00:00+00:00          NaN  \n",
       "...                                ...  \n",
       "2021-12-31 18:00:00+00:00    99.421761  \n",
       "2021-12-31 19:00:00+00:00   103.315829  \n",
       "2021-12-31 20:00:00+00:00   105.380492  \n",
       "2021-12-31 21:00:00+00:00   103.763064  \n",
       "2021-12-31 22:00:00+00:00    97.016161  \n",
       "\n",
       "[26304 rows x 169 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf76ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df1.drop('MWh', axis=1)  # Features\n",
    "y1 = df1['MWh']  # Target variable\n",
    "\n",
    "X_train1 = X1[168:21000]\n",
    "y_train1 = y1[168:21000]\n",
    "X_test1 = X1[21168:]\n",
    "y_test1 = y1[21168:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c538e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 42840\n",
      "[LightGBM] [Info] Number of data points in the train set: 20832, number of used features: 168\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A100 80GB PCIe, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 168 dense feature groups (3.34 MB) transferred to GPU in 0.014608 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 107.167990\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for LightGBM\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'device': 'gpu'  # Enable GPU support\n",
    "}\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "train_data1 = lgb.Dataset(X_train1, label=y_train1)\n",
    "# Train the model\n",
    "model1 = lgb.train(params, train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f46029e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.253771989787348"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred1 = model1.predict(X_test1)\n",
    "metrics.mean_absolute_error(y_test1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1992098c",
   "metadata": {},
   "source": [
    "# Predict value in 24 hours based on previous 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbf2ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24 = active_losses_df.copy()\n",
    "feature_columns = ['MWh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fd8462c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n",
      "/tmp/ipykernel_74458/1159104821.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df24[f'lag_{col}_{i}'] = df24[col].shift(i)\n"
     ]
    }
   ],
   "source": [
    "# Create lagged features\n",
    "for col in feature_columns:\n",
    "    for i in range(24, 8 * 24 + 1):  # for past 7 days (in hours)\n",
    "        df24[f'lag_{col}_{i}'] = df24[col].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d2c2f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWh</th>\n",
       "      <th>lag_MWh_24</th>\n",
       "      <th>lag_MWh_25</th>\n",
       "      <th>lag_MWh_26</th>\n",
       "      <th>lag_MWh_27</th>\n",
       "      <th>lag_MWh_28</th>\n",
       "      <th>lag_MWh_29</th>\n",
       "      <th>lag_MWh_30</th>\n",
       "      <th>lag_MWh_31</th>\n",
       "      <th>lag_MWh_32</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_MWh_183</th>\n",
       "      <th>lag_MWh_184</th>\n",
       "      <th>lag_MWh_185</th>\n",
       "      <th>lag_MWh_186</th>\n",
       "      <th>lag_MWh_187</th>\n",
       "      <th>lag_MWh_188</th>\n",
       "      <th>lag_MWh_189</th>\n",
       "      <th>lag_MWh_190</th>\n",
       "      <th>lag_MWh_191</th>\n",
       "      <th>lag_MWh_192</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+00:00</th>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>129.716036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>133.398074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>135.133852</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>131.699424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 18:00:00+00:00</th>\n",
       "      <td>171.707318</td>\n",
       "      <td>167.996507</td>\n",
       "      <td>180.606851</td>\n",
       "      <td>185.485353</td>\n",
       "      <td>196.837841</td>\n",
       "      <td>208.754417</td>\n",
       "      <td>185.553917</td>\n",
       "      <td>170.061282</td>\n",
       "      <td>157.021539</td>\n",
       "      <td>188.595906</td>\n",
       "      <td>...</td>\n",
       "      <td>119.037914</td>\n",
       "      <td>125.646293</td>\n",
       "      <td>104.161457</td>\n",
       "      <td>96.965601</td>\n",
       "      <td>98.765158</td>\n",
       "      <td>67.107170</td>\n",
       "      <td>68.907638</td>\n",
       "      <td>79.204443</td>\n",
       "      <td>71.702086</td>\n",
       "      <td>77.971249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00+00:00</th>\n",
       "      <td>159.462903</td>\n",
       "      <td>176.684491</td>\n",
       "      <td>167.996507</td>\n",
       "      <td>180.606851</td>\n",
       "      <td>185.485353</td>\n",
       "      <td>196.837841</td>\n",
       "      <td>208.754417</td>\n",
       "      <td>185.553917</td>\n",
       "      <td>170.061282</td>\n",
       "      <td>157.021539</td>\n",
       "      <td>...</td>\n",
       "      <td>118.070052</td>\n",
       "      <td>119.037914</td>\n",
       "      <td>125.646293</td>\n",
       "      <td>104.161457</td>\n",
       "      <td>96.965601</td>\n",
       "      <td>98.765158</td>\n",
       "      <td>67.107170</td>\n",
       "      <td>68.907638</td>\n",
       "      <td>79.204443</td>\n",
       "      <td>71.702086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00+00:00</th>\n",
       "      <td>155.109520</td>\n",
       "      <td>193.910195</td>\n",
       "      <td>176.684491</td>\n",
       "      <td>167.996507</td>\n",
       "      <td>180.606851</td>\n",
       "      <td>185.485353</td>\n",
       "      <td>196.837841</td>\n",
       "      <td>208.754417</td>\n",
       "      <td>185.553917</td>\n",
       "      <td>170.061282</td>\n",
       "      <td>...</td>\n",
       "      <td>106.971474</td>\n",
       "      <td>118.070052</td>\n",
       "      <td>119.037914</td>\n",
       "      <td>125.646293</td>\n",
       "      <td>104.161457</td>\n",
       "      <td>96.965601</td>\n",
       "      <td>98.765158</td>\n",
       "      <td>67.107170</td>\n",
       "      <td>68.907638</td>\n",
       "      <td>79.204443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00+00:00</th>\n",
       "      <td>171.370277</td>\n",
       "      <td>189.607597</td>\n",
       "      <td>193.910195</td>\n",
       "      <td>176.684491</td>\n",
       "      <td>167.996507</td>\n",
       "      <td>180.606851</td>\n",
       "      <td>185.485353</td>\n",
       "      <td>196.837841</td>\n",
       "      <td>208.754417</td>\n",
       "      <td>185.553917</td>\n",
       "      <td>...</td>\n",
       "      <td>106.122274</td>\n",
       "      <td>106.971474</td>\n",
       "      <td>118.070052</td>\n",
       "      <td>119.037914</td>\n",
       "      <td>125.646293</td>\n",
       "      <td>104.161457</td>\n",
       "      <td>96.965601</td>\n",
       "      <td>98.765158</td>\n",
       "      <td>67.107170</td>\n",
       "      <td>68.907638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00+00:00</th>\n",
       "      <td>146.054791</td>\n",
       "      <td>161.070379</td>\n",
       "      <td>189.607597</td>\n",
       "      <td>193.910195</td>\n",
       "      <td>176.684491</td>\n",
       "      <td>167.996507</td>\n",
       "      <td>180.606851</td>\n",
       "      <td>185.485353</td>\n",
       "      <td>196.837841</td>\n",
       "      <td>208.754417</td>\n",
       "      <td>...</td>\n",
       "      <td>98.921506</td>\n",
       "      <td>106.122274</td>\n",
       "      <td>106.971474</td>\n",
       "      <td>118.070052</td>\n",
       "      <td>119.037914</td>\n",
       "      <td>125.646293</td>\n",
       "      <td>104.161457</td>\n",
       "      <td>96.965601</td>\n",
       "      <td>98.765158</td>\n",
       "      <td>67.107170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MWh  lag_MWh_24  lag_MWh_25  lag_MWh_26  \\\n",
       "datetime                                                                    \n",
       "2018-12-31 23:00:00+00:00  139.525004         NaN         NaN         NaN   \n",
       "2019-01-01 00:00:00+00:00  129.716036         NaN         NaN         NaN   \n",
       "2019-01-01 01:00:00+00:00  133.398074         NaN         NaN         NaN   \n",
       "2019-01-01 02:00:00+00:00  135.133852         NaN         NaN         NaN   \n",
       "2019-01-01 03:00:00+00:00  131.699424         NaN         NaN         NaN   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  171.707318  167.996507  180.606851  185.485353   \n",
       "2021-12-31 19:00:00+00:00  159.462903  176.684491  167.996507  180.606851   \n",
       "2021-12-31 20:00:00+00:00  155.109520  193.910195  176.684491  167.996507   \n",
       "2021-12-31 21:00:00+00:00  171.370277  189.607597  193.910195  176.684491   \n",
       "2021-12-31 22:00:00+00:00  146.054791  161.070379  189.607597  193.910195   \n",
       "\n",
       "                           lag_MWh_27  lag_MWh_28  lag_MWh_29  lag_MWh_30  \\\n",
       "datetime                                                                    \n",
       "2018-12-31 23:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 00:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 01:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 02:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 03:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  196.837841  208.754417  185.553917  170.061282   \n",
       "2021-12-31 19:00:00+00:00  185.485353  196.837841  208.754417  185.553917   \n",
       "2021-12-31 20:00:00+00:00  180.606851  185.485353  196.837841  208.754417   \n",
       "2021-12-31 21:00:00+00:00  167.996507  180.606851  185.485353  196.837841   \n",
       "2021-12-31 22:00:00+00:00  176.684491  167.996507  180.606851  185.485353   \n",
       "\n",
       "                           lag_MWh_31  lag_MWh_32  ...  lag_MWh_183  \\\n",
       "datetime                                           ...                \n",
       "2018-12-31 23:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 00:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 01:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 02:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 03:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "...                               ...         ...  ...          ...   \n",
       "2021-12-31 18:00:00+00:00  157.021539  188.595906  ...   119.037914   \n",
       "2021-12-31 19:00:00+00:00  170.061282  157.021539  ...   118.070052   \n",
       "2021-12-31 20:00:00+00:00  185.553917  170.061282  ...   106.971474   \n",
       "2021-12-31 21:00:00+00:00  208.754417  185.553917  ...   106.122274   \n",
       "2021-12-31 22:00:00+00:00  196.837841  208.754417  ...    98.921506   \n",
       "\n",
       "                           lag_MWh_184  lag_MWh_185  lag_MWh_186  lag_MWh_187  \\\n",
       "datetime                                                                        \n",
       "2018-12-31 23:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00   125.646293   104.161457    96.965601    98.765158   \n",
       "2021-12-31 19:00:00+00:00   119.037914   125.646293   104.161457    96.965601   \n",
       "2021-12-31 20:00:00+00:00   118.070052   119.037914   125.646293   104.161457   \n",
       "2021-12-31 21:00:00+00:00   106.971474   118.070052   119.037914   125.646293   \n",
       "2021-12-31 22:00:00+00:00   106.122274   106.971474   118.070052   119.037914   \n",
       "\n",
       "                           lag_MWh_188  lag_MWh_189  lag_MWh_190  lag_MWh_191  \\\n",
       "datetime                                                                        \n",
       "2018-12-31 23:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00    67.107170    68.907638    79.204443    71.702086   \n",
       "2021-12-31 19:00:00+00:00    98.765158    67.107170    68.907638    79.204443   \n",
       "2021-12-31 20:00:00+00:00    96.965601    98.765158    67.107170    68.907638   \n",
       "2021-12-31 21:00:00+00:00   104.161457    96.965601    98.765158    67.107170   \n",
       "2021-12-31 22:00:00+00:00   125.646293   104.161457    96.965601    98.765158   \n",
       "\n",
       "                           lag_MWh_192  \n",
       "datetime                                \n",
       "2018-12-31 23:00:00+00:00          NaN  \n",
       "2019-01-01 00:00:00+00:00          NaN  \n",
       "2019-01-01 01:00:00+00:00          NaN  \n",
       "2019-01-01 02:00:00+00:00          NaN  \n",
       "2019-01-01 03:00:00+00:00          NaN  \n",
       "...                                ...  \n",
       "2021-12-31 18:00:00+00:00    77.971249  \n",
       "2021-12-31 19:00:00+00:00    71.702086  \n",
       "2021-12-31 20:00:00+00:00    79.204443  \n",
       "2021-12-31 21:00:00+00:00    68.907638  \n",
       "2021-12-31 22:00:00+00:00    67.107170  \n",
       "\n",
       "[26304 rows x 170 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4d5148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X24 = df24.drop('MWh', axis=1)  # Features\n",
    "y24 = df24['MWh']  # Target variable\n",
    "\n",
    "X_train24 = X24[194:21000]\n",
    "y_train24 = y24[194:21000]\n",
    "X_test24 = X24[21194:]\n",
    "y_test24 = y24[21194:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96608ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 43095\n",
      "[LightGBM] [Info] Number of data points in the train set: 20806, number of used features: 169\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A100 80GB PCIe, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 169 dense feature groups (3.41 MB) transferred to GPU in 0.009460 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 107.113329\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for LightGBM\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'device': 'gpu'  # Enable GPU support\n",
    "}\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "train_data24 = lgb.Dataset(X_train24, label=y_train24)\n",
    "# Train the model\n",
    "model24 = lgb.train(params, train_data24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bd2312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.831697540869342"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred24 = model24.predict(X_test24)\n",
    "metrics.mean_absolute_error(y_test24, y_pred24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf89ff0c",
   "metadata": {},
   "source": [
    "# Predict next 24 hours using predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd50ffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perdict_next_24hours(data_df: pd.DataFrame, date_input, model):\n",
    "    \"\"\"\n",
    "    Predict next hour based on last 7 days\n",
    "    Uses preditcion to computes next 24 hours\n",
    "    \"\"\"\n",
    "    input_data = data_df.loc[(data_df.index<date_input)&(data_df.index>(pd.to_datetime(date_input)-pd.Timedelta(days=7)))]\n",
    "    y_pred = []\n",
    "    for i in range(0,24):\n",
    "        y_pred += model.predict(input_data)\n",
    "        \n",
    "        #Remove first row\n",
    "        input_data = input_data[1:]\n",
    "        \n",
    "        #Add prediction to input\n",
    "        new_index = input_data.index[-1] + pd.Timedela('1H')\n",
    "        new_data = {\"value\": y_pred}\n",
    "        new_row = pd.DataFrame(new_data, index=new_index)\n",
    "        df = pd.concat([df, new_row])\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff510a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_74458/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n"
     ]
    }
   ],
   "source": [
    "df = active_losses_df.copy()\n",
    "feature_columns = ['MWh']\n",
    "for col in feature_columns:\n",
    "    for i in range(1, 7 * 24 + 1):  # for past 7 days (in hours)\n",
    "        df[f'lag_{col}_{i}'] = df[col].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eff1341",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MWh', axis=1)  # Features\n",
    "y = df['MWh']  # Target variable\n",
    "\n",
    "X_train = X[168:21000]\n",
    "y_train = y[168:21000]\n",
    "X_test = X[21168:]\n",
    "y_test = y[21168:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8383eb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 42840\n",
      "[LightGBM] [Info] Number of data points in the train set: 20832, number of used features: 168\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A100 80GB PCIe, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 168 dense feature groups (3.34 MB) transferred to GPU in 0.009906 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 107.167990\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for LightGBM\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'device': 'gpu'  # Enable GPU support\n",
    "}\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "# Train the model\n",
    "model = lgb.train(params, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b5530b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.253456776098483"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "metrics.mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "311f8d01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lag_MWh_1</th>\n",
       "      <th>lag_MWh_2</th>\n",
       "      <th>lag_MWh_3</th>\n",
       "      <th>lag_MWh_4</th>\n",
       "      <th>lag_MWh_5</th>\n",
       "      <th>lag_MWh_6</th>\n",
       "      <th>lag_MWh_7</th>\n",
       "      <th>lag_MWh_8</th>\n",
       "      <th>lag_MWh_9</th>\n",
       "      <th>lag_MWh_10</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_MWh_159</th>\n",
       "      <th>lag_MWh_160</th>\n",
       "      <th>lag_MWh_161</th>\n",
       "      <th>lag_MWh_162</th>\n",
       "      <th>lag_MWh_163</th>\n",
       "      <th>lag_MWh_164</th>\n",
       "      <th>lag_MWh_165</th>\n",
       "      <th>lag_MWh_166</th>\n",
       "      <th>lag_MWh_167</th>\n",
       "      <th>lag_MWh_168</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-31 23:00:00+00:00</th>\n",
       "      <td>67.218899</td>\n",
       "      <td>49.242383</td>\n",
       "      <td>63.917102</td>\n",
       "      <td>71.164044</td>\n",
       "      <td>81.454805</td>\n",
       "      <td>71.206708</td>\n",
       "      <td>49.922777</td>\n",
       "      <td>76.609783</td>\n",
       "      <td>88.785917</td>\n",
       "      <td>79.979536</td>\n",
       "      <td>...</td>\n",
       "      <td>51.056766</td>\n",
       "      <td>58.015912</td>\n",
       "      <td>70.450986</td>\n",
       "      <td>68.062951</td>\n",
       "      <td>58.894816</td>\n",
       "      <td>68.812508</td>\n",
       "      <td>87.429647</td>\n",
       "      <td>88.092732</td>\n",
       "      <td>82.766460</td>\n",
       "      <td>79.161570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 00:00:00+00:00</th>\n",
       "      <td>64.943005</td>\n",
       "      <td>67.218899</td>\n",
       "      <td>49.242383</td>\n",
       "      <td>63.917102</td>\n",
       "      <td>71.164044</td>\n",
       "      <td>81.454805</td>\n",
       "      <td>71.206708</td>\n",
       "      <td>49.922777</td>\n",
       "      <td>76.609783</td>\n",
       "      <td>88.785917</td>\n",
       "      <td>...</td>\n",
       "      <td>47.930903</td>\n",
       "      <td>51.056766</td>\n",
       "      <td>58.015912</td>\n",
       "      <td>70.450986</td>\n",
       "      <td>68.062951</td>\n",
       "      <td>58.894816</td>\n",
       "      <td>68.812508</td>\n",
       "      <td>87.429647</td>\n",
       "      <td>88.092732</td>\n",
       "      <td>82.766460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 01:00:00+00:00</th>\n",
       "      <td>73.370302</td>\n",
       "      <td>64.943005</td>\n",
       "      <td>67.218899</td>\n",
       "      <td>49.242383</td>\n",
       "      <td>63.917102</td>\n",
       "      <td>71.164044</td>\n",
       "      <td>81.454805</td>\n",
       "      <td>71.206708</td>\n",
       "      <td>49.922777</td>\n",
       "      <td>76.609783</td>\n",
       "      <td>...</td>\n",
       "      <td>47.399968</td>\n",
       "      <td>47.930903</td>\n",
       "      <td>51.056766</td>\n",
       "      <td>58.015912</td>\n",
       "      <td>70.450986</td>\n",
       "      <td>68.062951</td>\n",
       "      <td>58.894816</td>\n",
       "      <td>68.812508</td>\n",
       "      <td>87.429647</td>\n",
       "      <td>88.092732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 02:00:00+00:00</th>\n",
       "      <td>73.441925</td>\n",
       "      <td>73.370302</td>\n",
       "      <td>64.943005</td>\n",
       "      <td>67.218899</td>\n",
       "      <td>49.242383</td>\n",
       "      <td>63.917102</td>\n",
       "      <td>71.164044</td>\n",
       "      <td>81.454805</td>\n",
       "      <td>71.206708</td>\n",
       "      <td>49.922777</td>\n",
       "      <td>...</td>\n",
       "      <td>56.537030</td>\n",
       "      <td>47.399968</td>\n",
       "      <td>47.930903</td>\n",
       "      <td>51.056766</td>\n",
       "      <td>58.015912</td>\n",
       "      <td>70.450986</td>\n",
       "      <td>68.062951</td>\n",
       "      <td>58.894816</td>\n",
       "      <td>68.812508</td>\n",
       "      <td>87.429647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-01 03:00:00+00:00</th>\n",
       "      <td>70.316996</td>\n",
       "      <td>73.441925</td>\n",
       "      <td>73.370302</td>\n",
       "      <td>64.943005</td>\n",
       "      <td>67.218899</td>\n",
       "      <td>49.242383</td>\n",
       "      <td>63.917102</td>\n",
       "      <td>71.164044</td>\n",
       "      <td>81.454805</td>\n",
       "      <td>71.206708</td>\n",
       "      <td>...</td>\n",
       "      <td>60.612543</td>\n",
       "      <td>56.537030</td>\n",
       "      <td>47.399968</td>\n",
       "      <td>47.930903</td>\n",
       "      <td>51.056766</td>\n",
       "      <td>58.015912</td>\n",
       "      <td>70.450986</td>\n",
       "      <td>68.062951</td>\n",
       "      <td>58.894816</td>\n",
       "      <td>68.812508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 18:00:00+00:00</th>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>149.349078</td>\n",
       "      <td>173.862971</td>\n",
       "      <td>...</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>103.315829</td>\n",
       "      <td>99.421761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00+00:00</th>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>149.349078</td>\n",
       "      <td>...</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>103.315829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00+00:00</th>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>...</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00+00:00</th>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>...</td>\n",
       "      <td>136.717219</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00+00:00</th>\n",
       "      <td>171.370277</td>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>...</td>\n",
       "      <td>136.431471</td>\n",
       "      <td>136.717219</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5136 rows × 168 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            lag_MWh_1   lag_MWh_2   lag_MWh_3   lag_MWh_4  \\\n",
       "datetime                                                                    \n",
       "2021-05-31 23:00:00+00:00   67.218899   49.242383   63.917102   71.164044   \n",
       "2021-06-01 00:00:00+00:00   64.943005   67.218899   49.242383   63.917102   \n",
       "2021-06-01 01:00:00+00:00   73.370302   64.943005   67.218899   49.242383   \n",
       "2021-06-01 02:00:00+00:00   73.441925   73.370302   64.943005   67.218899   \n",
       "2021-06-01 03:00:00+00:00   70.316996   73.441925   73.370302   64.943005   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  152.159763  162.995636  188.541866  176.617953   \n",
       "2021-12-31 19:00:00+00:00  171.707318  152.159763  162.995636  188.541866   \n",
       "2021-12-31 20:00:00+00:00  159.462903  171.707318  152.159763  162.995636   \n",
       "2021-12-31 21:00:00+00:00  155.109520  159.462903  171.707318  152.159763   \n",
       "2021-12-31 22:00:00+00:00  171.370277  155.109520  159.462903  171.707318   \n",
       "\n",
       "                            lag_MWh_5   lag_MWh_6   lag_MWh_7   lag_MWh_8  \\\n",
       "datetime                                                                    \n",
       "2021-05-31 23:00:00+00:00   81.454805   71.206708   49.922777   76.609783   \n",
       "2021-06-01 00:00:00+00:00   71.164044   81.454805   71.206708   49.922777   \n",
       "2021-06-01 01:00:00+00:00   63.917102   71.164044   81.454805   71.206708   \n",
       "2021-06-01 02:00:00+00:00   49.242383   63.917102   71.164044   81.454805   \n",
       "2021-06-01 03:00:00+00:00   67.218899   49.242383   63.917102   71.164044   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  167.343565  145.792085  152.648212  150.967027   \n",
       "2021-12-31 19:00:00+00:00  176.617953  167.343565  145.792085  152.648212   \n",
       "2021-12-31 20:00:00+00:00  188.541866  176.617953  167.343565  145.792085   \n",
       "2021-12-31 21:00:00+00:00  162.995636  188.541866  176.617953  167.343565   \n",
       "2021-12-31 22:00:00+00:00  152.159763  162.995636  188.541866  176.617953   \n",
       "\n",
       "                            lag_MWh_9  lag_MWh_10  ...  lag_MWh_159  \\\n",
       "datetime                                           ...                \n",
       "2021-05-31 23:00:00+00:00   88.785917   79.979536  ...    51.056766   \n",
       "2021-06-01 00:00:00+00:00   76.609783   88.785917  ...    47.930903   \n",
       "2021-06-01 01:00:00+00:00   49.922777   76.609783  ...    47.399968   \n",
       "2021-06-01 02:00:00+00:00   71.206708   49.922777  ...    56.537030   \n",
       "2021-06-01 03:00:00+00:00   81.454805   71.206708  ...    60.612543   \n",
       "...                               ...         ...  ...          ...   \n",
       "2021-12-31 18:00:00+00:00  149.349078  173.862971  ...   125.661865   \n",
       "2021-12-31 19:00:00+00:00  150.967027  149.349078  ...   136.132174   \n",
       "2021-12-31 20:00:00+00:00  152.648212  150.967027  ...   144.984402   \n",
       "2021-12-31 21:00:00+00:00  145.792085  152.648212  ...   136.717219   \n",
       "2021-12-31 22:00:00+00:00  167.343565  145.792085  ...   136.431471   \n",
       "\n",
       "                           lag_MWh_160  lag_MWh_161  lag_MWh_162  lag_MWh_163  \\\n",
       "datetime                                                                        \n",
       "2021-05-31 23:00:00+00:00    58.015912    70.450986    68.062951    58.894816   \n",
       "2021-06-01 00:00:00+00:00    51.056766    58.015912    70.450986    68.062951   \n",
       "2021-06-01 01:00:00+00:00    47.930903    51.056766    58.015912    70.450986   \n",
       "2021-06-01 02:00:00+00:00    47.399968    47.930903    51.056766    58.015912   \n",
       "2021-06-01 03:00:00+00:00    56.537030    47.399968    47.930903    51.056766   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00   119.124221   115.795738   103.814345    97.836516   \n",
       "2021-12-31 19:00:00+00:00   125.661865   119.124221   115.795738   103.814345   \n",
       "2021-12-31 20:00:00+00:00   136.132174   125.661865   119.124221   115.795738   \n",
       "2021-12-31 21:00:00+00:00   144.984402   136.132174   125.661865   119.124221   \n",
       "2021-12-31 22:00:00+00:00   136.717219   144.984402   136.132174   125.661865   \n",
       "\n",
       "                           lag_MWh_164  lag_MWh_165  lag_MWh_166  lag_MWh_167  \\\n",
       "datetime                                                                        \n",
       "2021-05-31 23:00:00+00:00    68.812508    87.429647    88.092732    82.766460   \n",
       "2021-06-01 00:00:00+00:00    58.894816    68.812508    87.429647    88.092732   \n",
       "2021-06-01 01:00:00+00:00    68.062951    58.894816    68.812508    87.429647   \n",
       "2021-06-01 02:00:00+00:00    70.450986    68.062951    58.894816    68.812508   \n",
       "2021-06-01 03:00:00+00:00    58.015912    70.450986    68.062951    58.894816   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00    97.016161   103.763064   105.380492   103.315829   \n",
       "2021-12-31 19:00:00+00:00    97.836516    97.016161   103.763064   105.380492   \n",
       "2021-12-31 20:00:00+00:00   103.814345    97.836516    97.016161   103.763064   \n",
       "2021-12-31 21:00:00+00:00   115.795738   103.814345    97.836516    97.016161   \n",
       "2021-12-31 22:00:00+00:00   119.124221   115.795738   103.814345    97.836516   \n",
       "\n",
       "                           lag_MWh_168  \n",
       "datetime                                \n",
       "2021-05-31 23:00:00+00:00    79.161570  \n",
       "2021-06-01 00:00:00+00:00    82.766460  \n",
       "2021-06-01 01:00:00+00:00    88.092732  \n",
       "2021-06-01 02:00:00+00:00    87.429647  \n",
       "2021-06-01 03:00:00+00:00    68.812508  \n",
       "...                                ...  \n",
       "2021-12-31 18:00:00+00:00    99.421761  \n",
       "2021-12-31 19:00:00+00:00   103.315829  \n",
       "2021-12-31 20:00:00+00:00   105.380492  \n",
       "2021-12-31 21:00:00+00:00   103.763064  \n",
       "2021-12-31 22:00:00+00:00    97.016161  \n",
       "\n",
       "[5136 rows x 168 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf0164eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid comparison between dtype=datetime64[ns, UTC] and Timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:565\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_compatible_with\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, IncompatibleFrequency) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;66;03m# e.g. tzawareness mismatch\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:522\u001b[0m, in \u001b[0;36mDatetimeArray._check_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 522\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert_tzawareness_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/arrays/datetimes.py:748\u001b[0m, in \u001b[0;36mDatetimeArray._assert_tzawareness_compat\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m other_tz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 748\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    749\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot compare tz-naive and tz-aware datetime-like objects\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    750\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot compare tz-naive and tz-aware datetime-like objects",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mInvalidComparison\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:935\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_comparison_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:568\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._validate_comparison_value\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    566\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, IncompatibleFrequency) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;66;03m# e.g. tzawareness mismatch\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidComparison(other) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(other):\n",
      "\u001b[0;31mInvalidComparison\u001b[0m: 2021-05-24 00:00:00",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mperdict_next_24hours\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2021-05-31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[34], line 6\u001b[0m, in \u001b[0;36mperdict_next_24hours\u001b[0;34m(data_df, date_input, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperdict_next_24hours\u001b[39m(data_df: pd\u001b[38;5;241m.\u001b[39mDataFrame, date_input, model):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Predict next hour based on last 7 days\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    Uses preditcion to computes next 24 hours\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     input_data \u001b[38;5;241m=\u001b[39m data_df\u001b[38;5;241m.\u001b[39mloc[(data_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m<\u001b[39mdate_input)\u001b[38;5;241m&\u001b[39m(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate_input\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)]\n\u001b[1;32m      7\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m24\u001b[39m):\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/arraylike.py:56\u001b[0m, in \u001b[0;36mOpsMixin.__gt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__gt__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/indexes/base.py:6774\u001b[0m, in \u001b[0;36mIndex._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6771\u001b[0m         result \u001b[38;5;241m=\u001b[39m op(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, other)\n\u001b[1;32m   6773\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values, ExtensionArray):\n\u001b[0;32m-> 6774\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCMultiIndex):\n\u001b[1;32m   6777\u001b[0m     \u001b[38;5;66;03m# don't pass MultiIndex\u001b[39;00m\n\u001b[1;32m   6778\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/arraylike.py:56\u001b[0m, in \u001b[0;36mOpsMixin.__gt__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__gt__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__gt__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:937\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m    935\u001b[0m     other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_comparison_value(other)\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidComparison:\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minvalid_comparison\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype):\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;66;03m# We have to use comp_method_OBJECT_ARRAY instead of numpy\u001b[39;00m\n\u001b[1;32m    942\u001b[0m     \u001b[38;5;66;03m#  comparison otherwise it would fail to raise when\u001b[39;00m\n\u001b[1;32m    943\u001b[0m     \u001b[38;5;66;03m#  comparing tz-aware and tz-naive\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/ops/invalid.py:36\u001b[0m, in \u001b[0;36minvalid_comparison\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     typ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(right)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid comparison between dtype=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mleft\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid comparison between dtype=datetime64[ns, UTC] and Timestamp"
     ]
    }
   ],
   "source": [
    "perdict_next_24hours(data_df=df, date_input='2021-05-31', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e62571b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2018-12-31 23:00:00+0000', tz='UTC')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942e105",
   "metadata": {},
   "source": [
    "# Using Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87929a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with a date index\n",
    "date_index = active_losses_df.index.date\n",
    "new_df = pd.DataFrame(index=date_index)\n",
    "\n",
    "# Initialize an empty array for each date with 24 values\n",
    "new_df['MWh'] = [np.array([np.nan] * 24) for _ in range(len(date_index))]\n",
    "\n",
    "# Populate the array with the hourly values\n",
    "for date in date_index:\n",
    "    #hourly_values = active_losses_df.loc[date.strftime('%Y-%m-%d')]['MWh'].values\n",
    "    #new_df.at[date, 'MWh'][:len(hourly_values)] = hourly_values\n",
    "    \n",
    "    date_values = active_losses_df.loc[date.strftime('%Y-%m-%d')]\n",
    "    #print(date_values)\n",
    "    #print(date_values['MWh'].values)\n",
    "    new_df.loc[date] = date_values.values\n",
    "\n",
    "# Optional: Fill NaN values with zeros\n",
    "new_df['MWh'] = new_df['MWh'].apply(lambda x: np.nan_to_num(x, nan=0))\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "#print(new_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63d2f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 23:00:00+00:00</td>\n",
       "      <td>39.143346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 23:15:00+00:00</td>\n",
       "      <td>32.788069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 23:30:00+00:00</td>\n",
       "      <td>33.018916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 23:45:00+00:00</td>\n",
       "      <td>34.574673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:00:00+00:00</td>\n",
       "      <td>33.417096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105211</th>\n",
       "      <td>2021-12-31 21:45:00+00:00</td>\n",
       "      <td>40.720617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105212</th>\n",
       "      <td>2021-12-31 22:00:00+00:00</td>\n",
       "      <td>38.156039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105213</th>\n",
       "      <td>2021-12-31 22:15:00+00:00</td>\n",
       "      <td>36.290837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105214</th>\n",
       "      <td>2021-12-31 22:30:00+00:00</td>\n",
       "      <td>35.947704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105215</th>\n",
       "      <td>2021-12-31 22:45:00+00:00</td>\n",
       "      <td>35.660212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105216 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        datetime        MWh\n",
       "0      2018-12-31 23:00:00+00:00  39.143346\n",
       "1      2018-12-31 23:15:00+00:00  32.788069\n",
       "2      2018-12-31 23:30:00+00:00  33.018916\n",
       "3      2018-12-31 23:45:00+00:00  34.574673\n",
       "4      2019-01-01 00:00:00+00:00  33.417096\n",
       "...                          ...        ...\n",
       "105211 2021-12-31 21:45:00+00:00  40.720617\n",
       "105212 2021-12-31 22:00:00+00:00  38.156039\n",
       "105213 2021-12-31 22:15:00+00:00  36.290837\n",
       "105214 2021-12-31 22:30:00+00:00  35.947704\n",
       "105215 2021-12-31 22:45:00+00:00  35.660212\n",
       "\n",
       "[105216 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07bd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second index that repeats from 1 to 8\n",
    "df['sample_index'] = (df.reset_index().index // 8) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43f891ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWh</th>\n",
       "      <th>sample_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+00:00</th>\n",
       "      <td>39.143346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:15:00+00:00</th>\n",
       "      <td>32.788069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:30:00+00:00</th>\n",
       "      <td>33.018916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:45:00+00:00</th>\n",
       "      <td>34.574673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>33.417096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:15:00+00:00</th>\n",
       "      <td>34.716826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00+00:00</th>\n",
       "      <td>31.063598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:45:00+00:00</th>\n",
       "      <td>30.518516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>33.344467</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:15:00+00:00</th>\n",
       "      <td>33.763342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:30:00+00:00</th>\n",
       "      <td>32.771700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:45:00+00:00</th>\n",
       "      <td>33.518566</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>34.002476</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:15:00+00:00</th>\n",
       "      <td>33.340004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:30:00+00:00</th>\n",
       "      <td>34.326499</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:45:00+00:00</th>\n",
       "      <td>33.464873</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>32.459205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:15:00+00:00</th>\n",
       "      <td>32.300494</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:30:00+00:00</th>\n",
       "      <td>34.714438</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:45:00+00:00</th>\n",
       "      <td>32.225288</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MWh  sample_index\n",
       "datetime                                          \n",
       "2018-12-31 23:00:00+00:00  39.143346             1\n",
       "2018-12-31 23:15:00+00:00  32.788069             1\n",
       "2018-12-31 23:30:00+00:00  33.018916             1\n",
       "2018-12-31 23:45:00+00:00  34.574673             1\n",
       "2019-01-01 00:00:00+00:00  33.417096             1\n",
       "2019-01-01 00:15:00+00:00  34.716826             1\n",
       "2019-01-01 00:30:00+00:00  31.063598             1\n",
       "2019-01-01 00:45:00+00:00  30.518516             1\n",
       "2019-01-01 01:00:00+00:00  33.344467             2\n",
       "2019-01-01 01:15:00+00:00  33.763342             2\n",
       "2019-01-01 01:30:00+00:00  32.771700             2\n",
       "2019-01-01 01:45:00+00:00  33.518566             2\n",
       "2019-01-01 02:00:00+00:00  34.002476             2\n",
       "2019-01-01 02:15:00+00:00  33.340004             2\n",
       "2019-01-01 02:30:00+00:00  34.326499             2\n",
       "2019-01-01 02:45:00+00:00  33.464873             2\n",
       "2019-01-01 03:00:00+00:00  32.459205             3\n",
       "2019-01-01 03:15:00+00:00  32.300494             3\n",
       "2019-01-01 03:30:00+00:00  34.714438             3\n",
       "2019-01-01 03:45:00+00:00  32.225288             3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44c19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
