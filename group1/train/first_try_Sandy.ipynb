{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a284d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bd20ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWh</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+00:00</th>\n",
       "      <td>139.525004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>129.716036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>133.398074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>135.133852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>131.699424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 18:00:00+00:00</th>\n",
       "      <td>171.707318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00+00:00</th>\n",
       "      <td>159.462903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00+00:00</th>\n",
       "      <td>155.109520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00+00:00</th>\n",
       "      <td>171.370277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00+00:00</th>\n",
       "      <td>146.054791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MWh\n",
       "datetime                             \n",
       "2018-12-31 23:00:00+00:00  139.525004\n",
       "2019-01-01 00:00:00+00:00  129.716036\n",
       "2019-01-01 01:00:00+00:00  133.398074\n",
       "2019-01-01 02:00:00+00:00  135.133852\n",
       "2019-01-01 03:00:00+00:00  131.699424\n",
       "...                               ...\n",
       "2021-12-31 18:00:00+00:00  171.707318\n",
       "2021-12-31 19:00:00+00:00  159.462903\n",
       "2021-12-31 20:00:00+00:00  155.109520\n",
       "2021-12-31 21:00:00+00:00  171.370277\n",
       "2021-12-31 22:00:00+00:00  146.054791\n",
       "\n",
       "[26304 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_losses_df = pd.read_csv(\n",
    "    \"../data/Avtice-losses.csv\", skiprows=2, names=[\"datetime\", \"MWh\"], parse_dates=[\"datetime\"], index_col=\"datetime\")\n",
    "\n",
    "active_losses_df.index = active_losses_df.tz_localize('Europe/Brussels', ambiguous=\"infer\").tz_convert('UTC').index\n",
    "active_losses_df.index = active_losses_df.index - pd.Timedelta(minutes=15)\n",
    "active_losses_df = active_losses_df.resample('1H').sum()\n",
    "active_losses_df[\"MWh\"] = active_losses_df[\"MWh\"]/1000\n",
    "active_losses_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff5186e",
   "metadata": {},
   "source": [
    "# Predict next hour based on last 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b1a14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = active_losses_df.copy()\n",
    "feature_columns = ['MWh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a48519",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n",
      "/tmp/ipykernel_99872/4144301521.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df1[f'lag_{col}_{i}'] = df1[col].shift(i)\n"
     ]
    }
   ],
   "source": [
    "# Create lagged features\n",
    "for col in feature_columns:\n",
    "    for i in range(1, 7 * 24 + 1):  # for past 7 days (in hours)\n",
    "        df1[f'lag_{col}_{i}'] = df1[col].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f464105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWh</th>\n",
       "      <th>lag_MWh_1</th>\n",
       "      <th>lag_MWh_2</th>\n",
       "      <th>lag_MWh_3</th>\n",
       "      <th>lag_MWh_4</th>\n",
       "      <th>lag_MWh_5</th>\n",
       "      <th>lag_MWh_6</th>\n",
       "      <th>lag_MWh_7</th>\n",
       "      <th>lag_MWh_8</th>\n",
       "      <th>lag_MWh_9</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_MWh_159</th>\n",
       "      <th>lag_MWh_160</th>\n",
       "      <th>lag_MWh_161</th>\n",
       "      <th>lag_MWh_162</th>\n",
       "      <th>lag_MWh_163</th>\n",
       "      <th>lag_MWh_164</th>\n",
       "      <th>lag_MWh_165</th>\n",
       "      <th>lag_MWh_166</th>\n",
       "      <th>lag_MWh_167</th>\n",
       "      <th>lag_MWh_168</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+00:00</th>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>135.133852</td>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>131.699424</td>\n",
       "      <td>135.133852</td>\n",
       "      <td>133.398074</td>\n",
       "      <td>129.716036</td>\n",
       "      <td>139.525004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 18:00:00+00:00</th>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>149.349078</td>\n",
       "      <td>...</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>103.315829</td>\n",
       "      <td>99.421761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 19:00:00+00:00</th>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>150.967027</td>\n",
       "      <td>...</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "      <td>103.315829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 20:00:00+00:00</th>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>152.648212</td>\n",
       "      <td>...</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "      <td>105.380492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 21:00:00+00:00</th>\n",
       "      <td>171.370277</td>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>145.792085</td>\n",
       "      <td>...</td>\n",
       "      <td>136.717219</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "      <td>103.763064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31 22:00:00+00:00</th>\n",
       "      <td>146.054791</td>\n",
       "      <td>171.370277</td>\n",
       "      <td>155.109520</td>\n",
       "      <td>159.462903</td>\n",
       "      <td>171.707318</td>\n",
       "      <td>152.159763</td>\n",
       "      <td>162.995636</td>\n",
       "      <td>188.541866</td>\n",
       "      <td>176.617953</td>\n",
       "      <td>167.343565</td>\n",
       "      <td>...</td>\n",
       "      <td>136.431471</td>\n",
       "      <td>136.717219</td>\n",
       "      <td>144.984402</td>\n",
       "      <td>136.132174</td>\n",
       "      <td>125.661865</td>\n",
       "      <td>119.124221</td>\n",
       "      <td>115.795738</td>\n",
       "      <td>103.814345</td>\n",
       "      <td>97.836516</td>\n",
       "      <td>97.016161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26304 rows × 169 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  MWh   lag_MWh_1   lag_MWh_2   lag_MWh_3  \\\n",
       "datetime                                                                    \n",
       "2018-12-31 23:00:00+00:00  139.525004         NaN         NaN         NaN   \n",
       "2019-01-01 00:00:00+00:00  129.716036  139.525004         NaN         NaN   \n",
       "2019-01-01 01:00:00+00:00  133.398074  129.716036  139.525004         NaN   \n",
       "2019-01-01 02:00:00+00:00  135.133852  133.398074  129.716036  139.525004   \n",
       "2019-01-01 03:00:00+00:00  131.699424  135.133852  133.398074  129.716036   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  171.707318  152.159763  162.995636  188.541866   \n",
       "2021-12-31 19:00:00+00:00  159.462903  171.707318  152.159763  162.995636   \n",
       "2021-12-31 20:00:00+00:00  155.109520  159.462903  171.707318  152.159763   \n",
       "2021-12-31 21:00:00+00:00  171.370277  155.109520  159.462903  171.707318   \n",
       "2021-12-31 22:00:00+00:00  146.054791  171.370277  155.109520  159.462903   \n",
       "\n",
       "                            lag_MWh_4   lag_MWh_5   lag_MWh_6   lag_MWh_7  \\\n",
       "datetime                                                                    \n",
       "2018-12-31 23:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 00:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 01:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 02:00:00+00:00         NaN         NaN         NaN         NaN   \n",
       "2019-01-01 03:00:00+00:00  139.525004         NaN         NaN         NaN   \n",
       "...                               ...         ...         ...         ...   \n",
       "2021-12-31 18:00:00+00:00  176.617953  167.343565  145.792085  152.648212   \n",
       "2021-12-31 19:00:00+00:00  188.541866  176.617953  167.343565  145.792085   \n",
       "2021-12-31 20:00:00+00:00  162.995636  188.541866  176.617953  167.343565   \n",
       "2021-12-31 21:00:00+00:00  152.159763  162.995636  188.541866  176.617953   \n",
       "2021-12-31 22:00:00+00:00  171.707318  152.159763  162.995636  188.541866   \n",
       "\n",
       "                            lag_MWh_8   lag_MWh_9  ...  lag_MWh_159  \\\n",
       "datetime                                           ...                \n",
       "2018-12-31 23:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 00:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 01:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 02:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "2019-01-01 03:00:00+00:00         NaN         NaN  ...          NaN   \n",
       "...                               ...         ...  ...          ...   \n",
       "2021-12-31 18:00:00+00:00  150.967027  149.349078  ...   125.661865   \n",
       "2021-12-31 19:00:00+00:00  152.648212  150.967027  ...   136.132174   \n",
       "2021-12-31 20:00:00+00:00  145.792085  152.648212  ...   144.984402   \n",
       "2021-12-31 21:00:00+00:00  167.343565  145.792085  ...   136.717219   \n",
       "2021-12-31 22:00:00+00:00  176.617953  167.343565  ...   136.431471   \n",
       "\n",
       "                           lag_MWh_160  lag_MWh_161  lag_MWh_162  lag_MWh_163  \\\n",
       "datetime                                                                        \n",
       "2018-12-31 23:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00   119.124221   115.795738   103.814345    97.836516   \n",
       "2021-12-31 19:00:00+00:00   125.661865   119.124221   115.795738   103.814345   \n",
       "2021-12-31 20:00:00+00:00   136.132174   125.661865   119.124221   115.795738   \n",
       "2021-12-31 21:00:00+00:00   144.984402   136.132174   125.661865   119.124221   \n",
       "2021-12-31 22:00:00+00:00   136.717219   144.984402   136.132174   125.661865   \n",
       "\n",
       "                           lag_MWh_164  lag_MWh_165  lag_MWh_166  lag_MWh_167  \\\n",
       "datetime                                                                        \n",
       "2018-12-31 23:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 00:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 01:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 02:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "2019-01-01 03:00:00+00:00          NaN          NaN          NaN          NaN   \n",
       "...                                ...          ...          ...          ...   \n",
       "2021-12-31 18:00:00+00:00    97.016161   103.763064   105.380492   103.315829   \n",
       "2021-12-31 19:00:00+00:00    97.836516    97.016161   103.763064   105.380492   \n",
       "2021-12-31 20:00:00+00:00   103.814345    97.836516    97.016161   103.763064   \n",
       "2021-12-31 21:00:00+00:00   115.795738   103.814345    97.836516    97.016161   \n",
       "2021-12-31 22:00:00+00:00   119.124221   115.795738   103.814345    97.836516   \n",
       "\n",
       "                           lag_MWh_168  \n",
       "datetime                                \n",
       "2018-12-31 23:00:00+00:00          NaN  \n",
       "2019-01-01 00:00:00+00:00          NaN  \n",
       "2019-01-01 01:00:00+00:00          NaN  \n",
       "2019-01-01 02:00:00+00:00          NaN  \n",
       "2019-01-01 03:00:00+00:00          NaN  \n",
       "...                                ...  \n",
       "2021-12-31 18:00:00+00:00    99.421761  \n",
       "2021-12-31 19:00:00+00:00   103.315829  \n",
       "2021-12-31 20:00:00+00:00   105.380492  \n",
       "2021-12-31 21:00:00+00:00   103.763064  \n",
       "2021-12-31 22:00:00+00:00    97.016161  \n",
       "\n",
       "[26304 rows x 169 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf76ef14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = df1.drop('MWh', axis=1)  # Features\n",
    "y1 = df1['MWh']  # Target variable\n",
    "\n",
    "X_train1 = X1[168:21000]\n",
    "y_train1 = y1[168:21000]\n",
    "X_test1 = X1[21168:]\n",
    "y_test1 = y1[21168:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c538e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 42840\n",
      "[LightGBM] [Info] Number of data points in the train set: 20832, number of used features: 168\n",
      "[LightGBM] [Info] Using GPU Device: NVIDIA A100 80GB PCIe, Vendor: NVIDIA Corporation\n",
      "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
      "[LightGBM] [Info] GPU programs have been built\n",
      "[LightGBM] [Info] Size of histogram bin entry: 8\n",
      "[LightGBM] [Info] 168 dense feature groups (3.34 MB) transferred to GPU in 0.033963 secs. 0 sparse feature groups\n",
      "[LightGBM] [Info] Start training from score 107.167990\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters for LightGBM\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'device': 'gpu'  # Enable GPU support\n",
    "}\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "train_data1 = lgb.Dataset(X_train1, label=y_train1)\n",
    "# Train the model\n",
    "model1 = lgb.train(params, train_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f46029e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model1.predict(X_test1)\n",
    "metrics.mean_absolute_error(y_test1, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1992098c",
   "metadata": {},
   "source": [
    "# Predict value in 24 hours based on previous 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf2ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24 = active_losses_df.copy()\n",
    "feature_columns = ['MWh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd8462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagged features\n",
    "for col in feature_columns:\n",
    "    for i in range(24, 8 * 24 + 1):  # for past 7 days (in hours)\n",
    "        df24[f'lag_{col}_{i}'] = df24[col].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556470c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d5148d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X24 = df24.drop('MWh', axis=1)  # Features\n",
    "y24 = df24['MWh']  # Target variable\n",
    "\n",
    "X_train24 = X24[194:21000]\n",
    "y_train24 = y24[194:21000]\n",
    "X_test24 = X24[21194:]\n",
    "y_test24 = y24[21194:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96608ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters for LightGBM\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'device': 'gpu'  # Enable GPU support\n",
    "}\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "train_data24 = lgb.Dataset(X_train24, label=y_train24)\n",
    "# Train the model\n",
    "model24 = lgb.train(params, train_data24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4ed152",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred24 = model24.predict(X_test24)\n",
    "metrics.mean_absolute_error(y_test24, y_pred24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fc09c4",
   "metadata": {},
   "source": [
    "# Predict next 24 hours using predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0318c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perdict_next_24hours(data_df: pd.DataFrame, date_input, model):\n",
    "    \"\"\"\n",
    "    Predict next hour based on last 7 days\n",
    "    Uses preditcion to computes next 24 hours\n",
    "    \"\"\"\n",
    "    input_data = data_df.loc[data_df.index<date_input].tail(1)\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(0,24):\n",
    "        y_pred += model.predict(input_data)\n",
    "        \n",
    "        #Remove first column\n",
    "        input_data = input_data[1:]\n",
    "        input_data = input_data.shift(periods=1, axis=\"columns\")\n",
    "        input_data.iloc[:,0] = y_pred\n",
    "        print(input_data)\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03f81fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n",
      "/tmp/ipykernel_82785/2424762308.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'lag_{col}_{i}'] = df[col].shift(i)\n"
     ]
    }
   ],
   "source": [
    "df = active_losses_df.copy()\n",
    "feature_columns = ['MWh']\n",
    "for col in feature_columns:\n",
    "    for i in range(1, 7 * 24 + 1):  # for past 7 days (in hours)\n",
    "        df[f'lag_{col}_{i}'] = df[col].shift(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7479dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('MWh', axis=1)  # Features\n",
    "y = df['MWh']  # Target variable\n",
    "\n",
    "X_train = X[168:21000]\n",
    "y_train = y[168:21000]\n",
    "X_test = X[21168:]\n",
    "y_test = y[21168:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97c23be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.671838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 42840\n",
      "[LightGBM] [Info] Number of data points in the train set: 20832, number of used features: 168\n",
      "[LightGBM] [Info] Start training from score 107.167990\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m train_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_train, label\u001b[38;5;241m=\u001b[39my_train)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/lightgbm/engine.py:266\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    259\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    260\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    261\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    262\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    263\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    264\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 266\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/lightgbm/basic.py:3557\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3556\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3557\u001b[0m _safe_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3558\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3559\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   3560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameters for LightGBM\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'mae',\n",
    "    'device': 'gpu'  # Enable GPU support\n",
    "}\n",
    "\n",
    "# Create the LightGBM dataset\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "# Train the model\n",
    "model = lgb.train(params, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d475b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "metrics.mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec4964",
   "metadata": {},
   "outputs": [],
   "source": [
    "perdict_next_24hours(data_df=df, date_input=X_test.index[1], model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef431ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c25914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303caf53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c942e105",
   "metadata": {},
   "source": [
    "# Using Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87929a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with a date index\n",
    "date_index = active_losses_df.index.date\n",
    "new_df = pd.DataFrame(index=date_index)\n",
    "\n",
    "# Initialize an empty array for each date with 24 values\n",
    "new_df['MWh'] = [np.array([np.nan] * 24) for _ in range(len(date_index))]\n",
    "\n",
    "# Populate the array with the hourly values\n",
    "for date in date_index:\n",
    "    #hourly_values = active_losses_df.loc[date.strftime('%Y-%m-%d')]['MWh'].values\n",
    "    #new_df.at[date, 'MWh'][:len(hourly_values)] = hourly_values\n",
    "    \n",
    "    date_values = active_losses_df.loc[date.strftime('%Y-%m-%d')]\n",
    "    #print(date_values)\n",
    "    #print(date_values['MWh'].values)\n",
    "    new_df.loc[date] = date_values.values\n",
    "\n",
    "# Optional: Fill NaN values with zeros\n",
    "new_df['MWh'] = new_df['MWh'].apply(lambda x: np.nan_to_num(x, nan=0))\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "#print(new_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e63d2f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>MWh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-31 23:00:00+00:00</td>\n",
       "      <td>39.143346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-31 23:15:00+00:00</td>\n",
       "      <td>32.788069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-31 23:30:00+00:00</td>\n",
       "      <td>33.018916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-31 23:45:00+00:00</td>\n",
       "      <td>34.574673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 00:00:00+00:00</td>\n",
       "      <td>33.417096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105211</th>\n",
       "      <td>2021-12-31 21:45:00+00:00</td>\n",
       "      <td>40.720617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105212</th>\n",
       "      <td>2021-12-31 22:00:00+00:00</td>\n",
       "      <td>38.156039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105213</th>\n",
       "      <td>2021-12-31 22:15:00+00:00</td>\n",
       "      <td>36.290837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105214</th>\n",
       "      <td>2021-12-31 22:30:00+00:00</td>\n",
       "      <td>35.947704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105215</th>\n",
       "      <td>2021-12-31 22:45:00+00:00</td>\n",
       "      <td>35.660212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105216 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        datetime        MWh\n",
       "0      2018-12-31 23:00:00+00:00  39.143346\n",
       "1      2018-12-31 23:15:00+00:00  32.788069\n",
       "2      2018-12-31 23:30:00+00:00  33.018916\n",
       "3      2018-12-31 23:45:00+00:00  34.574673\n",
       "4      2019-01-01 00:00:00+00:00  33.417096\n",
       "...                          ...        ...\n",
       "105211 2021-12-31 21:45:00+00:00  40.720617\n",
       "105212 2021-12-31 22:00:00+00:00  38.156039\n",
       "105213 2021-12-31 22:15:00+00:00  36.290837\n",
       "105214 2021-12-31 22:30:00+00:00  35.947704\n",
       "105215 2021-12-31 22:45:00+00:00  35.660212\n",
       "\n",
       "[105216 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07bd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a second index that repeats from 1 to 8\n",
    "df['sample_index'] = (df.reset_index().index // 8) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43f891ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWh</th>\n",
       "      <th>sample_index</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:00:00+00:00</th>\n",
       "      <td>39.143346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:15:00+00:00</th>\n",
       "      <td>32.788069</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:30:00+00:00</th>\n",
       "      <td>33.018916</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-31 23:45:00+00:00</th>\n",
       "      <td>34.574673</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00+00:00</th>\n",
       "      <td>33.417096</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:15:00+00:00</th>\n",
       "      <td>34.716826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:30:00+00:00</th>\n",
       "      <td>31.063598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:45:00+00:00</th>\n",
       "      <td>30.518516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00+00:00</th>\n",
       "      <td>33.344467</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:15:00+00:00</th>\n",
       "      <td>33.763342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:30:00+00:00</th>\n",
       "      <td>32.771700</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:45:00+00:00</th>\n",
       "      <td>33.518566</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00+00:00</th>\n",
       "      <td>34.002476</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:15:00+00:00</th>\n",
       "      <td>33.340004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:30:00+00:00</th>\n",
       "      <td>34.326499</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:45:00+00:00</th>\n",
       "      <td>33.464873</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00+00:00</th>\n",
       "      <td>32.459205</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:15:00+00:00</th>\n",
       "      <td>32.300494</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:30:00+00:00</th>\n",
       "      <td>34.714438</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:45:00+00:00</th>\n",
       "      <td>32.225288</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 MWh  sample_index\n",
       "datetime                                          \n",
       "2018-12-31 23:00:00+00:00  39.143346             1\n",
       "2018-12-31 23:15:00+00:00  32.788069             1\n",
       "2018-12-31 23:30:00+00:00  33.018916             1\n",
       "2018-12-31 23:45:00+00:00  34.574673             1\n",
       "2019-01-01 00:00:00+00:00  33.417096             1\n",
       "2019-01-01 00:15:00+00:00  34.716826             1\n",
       "2019-01-01 00:30:00+00:00  31.063598             1\n",
       "2019-01-01 00:45:00+00:00  30.518516             1\n",
       "2019-01-01 01:00:00+00:00  33.344467             2\n",
       "2019-01-01 01:15:00+00:00  33.763342             2\n",
       "2019-01-01 01:30:00+00:00  32.771700             2\n",
       "2019-01-01 01:45:00+00:00  33.518566             2\n",
       "2019-01-01 02:00:00+00:00  34.002476             2\n",
       "2019-01-01 02:15:00+00:00  33.340004             2\n",
       "2019-01-01 02:30:00+00:00  34.326499             2\n",
       "2019-01-01 02:45:00+00:00  33.464873             2\n",
       "2019-01-01 03:00:00+00:00  32.459205             3\n",
       "2019-01-01 03:15:00+00:00  32.300494             3\n",
       "2019-01-01 03:30:00+00:00  34.714438             3\n",
       "2019-01-01 03:45:00+00:00  32.225288             3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44c19e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
