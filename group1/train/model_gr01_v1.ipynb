{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "424deec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Importing joblib for saving models\n",
    "\n",
    "import joblib\n",
    "torch.save(model.state_dict(), buffer)\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fbeb643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed_0.1_x</th>\n",
       "      <th>Unnamed_0_x</th>\n",
       "      <th>solar_fore_de_mw</th>\n",
       "      <th>solar_fore_it_mw</th>\n",
       "      <th>wind_fore_de_mw</th>\n",
       "      <th>wind_fore_it_mw</th>\n",
       "      <th>Unnamed_0.1_y</th>\n",
       "      <th>Unnamed_0_y</th>\n",
       "      <th>temperature_fore_ch</th>\n",
       "      <th>temperature_fore_fr</th>\n",
       "      <th>...</th>\n",
       "      <th>lag_std_mwh_15</th>\n",
       "      <th>lag_std_mwh_16</th>\n",
       "      <th>lag_std_mwh_17</th>\n",
       "      <th>lag_std_mwh_18</th>\n",
       "      <th>lag_std_mwh_19</th>\n",
       "      <th>lag_std_mwh_20</th>\n",
       "      <th>lag_std_mwh_21</th>\n",
       "      <th>lag_std_mwh_22</th>\n",
       "      <th>lag_std_mwh_23</th>\n",
       "      <th>lag_std_mwh_24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-02 00:00:00+00:00</th>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25033.75</td>\n",
       "      <td>2212.40</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.70</td>\n",
       "      <td>8.51</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 01:00:00+00:00</th>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25362.58</td>\n",
       "      <td>2161.55</td>\n",
       "      <td>26.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6.23</td>\n",
       "      <td>8.58</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 02:00:00+00:00</th>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25901.78</td>\n",
       "      <td>2053.93</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>5.96</td>\n",
       "      <td>8.73</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 03:00:00+00:00</th>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25747.25</td>\n",
       "      <td>1915.25</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.50</td>\n",
       "      <td>8.85</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02 04:00:00+00:00</th>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25784.95</td>\n",
       "      <td>1724.83</td>\n",
       "      <td>29.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5.35</td>\n",
       "      <td>8.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 18:00:00+00:00</th>\n",
       "      <td>8755.0</td>\n",
       "      <td>8755.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44107.32</td>\n",
       "      <td>569.68</td>\n",
       "      <td>8755.0</td>\n",
       "      <td>8755.0</td>\n",
       "      <td>10.37</td>\n",
       "      <td>14.18</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>22.227642</td>\n",
       "      <td>19.496665</td>\n",
       "      <td>14.182205</td>\n",
       "      <td>14.574242</td>\n",
       "      <td>15.963620</td>\n",
       "      <td>19.099247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 19:00:00+00:00</th>\n",
       "      <td>8756.0</td>\n",
       "      <td>8756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44512.60</td>\n",
       "      <td>459.45</td>\n",
       "      <td>8756.0</td>\n",
       "      <td>8756.0</td>\n",
       "      <td>9.67</td>\n",
       "      <td>13.90</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>22.227642</td>\n",
       "      <td>19.496665</td>\n",
       "      <td>14.182205</td>\n",
       "      <td>14.574242</td>\n",
       "      <td>15.963620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 20:00:00+00:00</th>\n",
       "      <td>8757.0</td>\n",
       "      <td>8757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44946.45</td>\n",
       "      <td>399.35</td>\n",
       "      <td>8757.0</td>\n",
       "      <td>8757.0</td>\n",
       "      <td>9.10</td>\n",
       "      <td>13.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>22.227642</td>\n",
       "      <td>19.496665</td>\n",
       "      <td>14.182205</td>\n",
       "      <td>14.574242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 21:00:00+00:00</th>\n",
       "      <td>8758.0</td>\n",
       "      <td>8758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44938.83</td>\n",
       "      <td>420.78</td>\n",
       "      <td>8758.0</td>\n",
       "      <td>8758.0</td>\n",
       "      <td>8.64</td>\n",
       "      <td>13.29</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>22.227642</td>\n",
       "      <td>19.496665</td>\n",
       "      <td>14.182205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31 22:00:00+00:00</th>\n",
       "      <td>8759.0</td>\n",
       "      <td>8759.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44693.53</td>\n",
       "      <td>501.10</td>\n",
       "      <td>8759.0</td>\n",
       "      <td>8759.0</td>\n",
       "      <td>8.25</td>\n",
       "      <td>13.20</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>22.227642</td>\n",
       "      <td>19.496665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8735 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Unnamed_0.1_x  Unnamed_0_x  solar_fore_de_mw  \\\n",
       "datetime                                                                  \n",
       "2022-01-02 00:00:00+00:00           25.0         25.0               0.0   \n",
       "2022-01-02 01:00:00+00:00           26.0         26.0               0.0   \n",
       "2022-01-02 02:00:00+00:00           27.0         27.0               0.0   \n",
       "2022-01-02 03:00:00+00:00           28.0         28.0               0.0   \n",
       "2022-01-02 04:00:00+00:00           29.0         29.0               0.0   \n",
       "...                                  ...          ...               ...   \n",
       "2022-12-31 18:00:00+00:00         8755.0       8755.0               0.0   \n",
       "2022-12-31 19:00:00+00:00         8756.0       8756.0               0.0   \n",
       "2022-12-31 20:00:00+00:00         8757.0       8757.0               0.0   \n",
       "2022-12-31 21:00:00+00:00         8758.0       8758.0               0.0   \n",
       "2022-12-31 22:00:00+00:00         8759.0       8759.0               0.0   \n",
       "\n",
       "                           solar_fore_it_mw  wind_fore_de_mw  wind_fore_it_mw  \\\n",
       "datetime                                                                        \n",
       "2022-01-02 00:00:00+00:00               0.0         25033.75          2212.40   \n",
       "2022-01-02 01:00:00+00:00               0.0         25362.58          2161.55   \n",
       "2022-01-02 02:00:00+00:00               0.0         25901.78          2053.93   \n",
       "2022-01-02 03:00:00+00:00               0.0         25747.25          1915.25   \n",
       "2022-01-02 04:00:00+00:00               0.0         25784.95          1724.83   \n",
       "...                                     ...              ...              ...   \n",
       "2022-12-31 18:00:00+00:00               0.0         44107.32           569.68   \n",
       "2022-12-31 19:00:00+00:00               0.0         44512.60           459.45   \n",
       "2022-12-31 20:00:00+00:00               0.0         44946.45           399.35   \n",
       "2022-12-31 21:00:00+00:00               0.0         44938.83           420.78   \n",
       "2022-12-31 22:00:00+00:00               0.0         44693.53           501.10   \n",
       "\n",
       "                           Unnamed_0.1_y  Unnamed_0_y  temperature_fore_ch  \\\n",
       "datetime                                                                     \n",
       "2022-01-02 00:00:00+00:00           25.0         25.0                 6.70   \n",
       "2022-01-02 01:00:00+00:00           26.0         26.0                 6.23   \n",
       "2022-01-02 02:00:00+00:00           27.0         27.0                 5.96   \n",
       "2022-01-02 03:00:00+00:00           28.0         28.0                 5.50   \n",
       "2022-01-02 04:00:00+00:00           29.0         29.0                 5.35   \n",
       "...                                  ...          ...                  ...   \n",
       "2022-12-31 18:00:00+00:00         8755.0       8755.0                10.37   \n",
       "2022-12-31 19:00:00+00:00         8756.0       8756.0                 9.67   \n",
       "2022-12-31 20:00:00+00:00         8757.0       8757.0                 9.10   \n",
       "2022-12-31 21:00:00+00:00         8758.0       8758.0                 8.64   \n",
       "2022-12-31 22:00:00+00:00         8759.0       8759.0                 8.25   \n",
       "\n",
       "                           temperature_fore_fr  ...  lag_std_mwh_15  \\\n",
       "datetime                                        ...                   \n",
       "2022-01-02 00:00:00+00:00                 8.51  ...            -1.0   \n",
       "2022-01-02 01:00:00+00:00                 8.58  ...            -1.0   \n",
       "2022-01-02 02:00:00+00:00                 8.73  ...            -1.0   \n",
       "2022-01-02 03:00:00+00:00                 8.85  ...            -1.0   \n",
       "2022-01-02 04:00:00+00:00                 8.93  ...            -1.0   \n",
       "...                                        ...  ...             ...   \n",
       "2022-12-31 18:00:00+00:00                14.18  ...            -1.0   \n",
       "2022-12-31 19:00:00+00:00                13.90  ...            -1.0   \n",
       "2022-12-31 20:00:00+00:00                13.57  ...            -1.0   \n",
       "2022-12-31 21:00:00+00:00                13.29  ...            -1.0   \n",
       "2022-12-31 22:00:00+00:00                13.20  ...            -1.0   \n",
       "\n",
       "                           lag_std_mwh_16  lag_std_mwh_17  lag_std_mwh_18  \\\n",
       "datetime                                                                    \n",
       "2022-01-02 00:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "2022-01-02 01:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "2022-01-02 02:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "2022-01-02 03:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "2022-01-02 04:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "...                                   ...             ...             ...   \n",
       "2022-12-31 18:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "2022-12-31 19:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "2022-12-31 20:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "2022-12-31 21:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "2022-12-31 22:00:00+00:00            -1.0            -1.0            -1.0   \n",
       "\n",
       "                           lag_std_mwh_19  lag_std_mwh_20  lag_std_mwh_21  \\\n",
       "datetime                                                                    \n",
       "2022-01-02 00:00:00+00:00       -1.000000       -1.000000       -1.000000   \n",
       "2022-01-02 01:00:00+00:00       -1.000000       -1.000000       -1.000000   \n",
       "2022-01-02 02:00:00+00:00       -1.000000       -1.000000       -1.000000   \n",
       "2022-01-02 03:00:00+00:00       -1.000000       -1.000000       -1.000000   \n",
       "2022-01-02 04:00:00+00:00       -1.000000       -1.000000       -1.000000   \n",
       "...                                   ...             ...             ...   \n",
       "2022-12-31 18:00:00+00:00       22.227642       19.496665       14.182205   \n",
       "2022-12-31 19:00:00+00:00       -1.000000       22.227642       19.496665   \n",
       "2022-12-31 20:00:00+00:00       -1.000000       -1.000000       22.227642   \n",
       "2022-12-31 21:00:00+00:00       -1.000000       -1.000000       -1.000000   \n",
       "2022-12-31 22:00:00+00:00       -1.000000       -1.000000       -1.000000   \n",
       "\n",
       "                           lag_std_mwh_22  lag_std_mwh_23  lag_std_mwh_24  \n",
       "datetime                                                                   \n",
       "2022-01-02 00:00:00+00:00       -1.000000       -1.000000       -1.000000  \n",
       "2022-01-02 01:00:00+00:00       -1.000000       -1.000000       -1.000000  \n",
       "2022-01-02 02:00:00+00:00       -1.000000       -1.000000       -1.000000  \n",
       "2022-01-02 03:00:00+00:00       -1.000000       -1.000000       -1.000000  \n",
       "2022-01-02 04:00:00+00:00       -1.000000       -1.000000       -1.000000  \n",
       "...                                   ...             ...             ...  \n",
       "2022-12-31 18:00:00+00:00       14.574242       15.963620       19.099247  \n",
       "2022-12-31 19:00:00+00:00       14.182205       14.574242       15.963620  \n",
       "2022-12-31 20:00:00+00:00       19.496665       14.182205       14.574242  \n",
       "2022-12-31 21:00:00+00:00       22.227642       19.496665       14.182205  \n",
       "2022-12-31 22:00:00+00:00       -1.000000       22.227642       19.496665  \n",
       "\n",
       "[8735 rows x 110 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1416bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"df1.csv\")\n",
    "df.set_index('datetime', inplace=True)\n",
    "# For DataFrame\n",
    "df = df.astype(float)\n",
    "\n",
    "# Sort the DataFrame by datetime\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "\n",
    "# Train-test split based on timestamp\n",
    "train_size = int(len(df) * 0.66)\n",
    "train, test = df.iloc[:train_size], df.iloc[train_size:]\n",
    "\n",
    "# Features and target\n",
    "X_train, y_train = train.drop('target', axis=1), train['target']\n",
    "X_test, y_test = test.drop('target', axis=1), test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2e91124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 18.598710085209344\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Fit the model on training data\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate the MAE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "985b4d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Train Loss: 18.1507, Val Loss: 16.3401\n",
      "Epoch [20/100], Train Loss: 17.7558, Val Loss: 16.3728\n",
      "Epoch [30/100], Train Loss: 17.3911, Val Loss: 16.1124\n",
      "Early stopping triggered\n",
      "Mean Absolute Error: 16.62011760137746\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "# Check CUDA and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Scale the features\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train.values).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test_scaled).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).to(device)\n",
    "\n",
    "# Create DataLoader for mini-batch gradient descent\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Define DNN model with dropout layers\n",
    "class DNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(DNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 256)\n",
    "        self.layer2 = nn.Linear(256, 64)\n",
    "        self.dropout = nn.Dropout(0.22)\n",
    "        self.layer3 = nn.Linear(64, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "input_dim = X_train.shape[1]\n",
    "model = DNN(input_dim).to(device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0008)\n",
    "\n",
    "# Early stopping initialization\n",
    "min_val_loss = float('inf')\n",
    "patience = 10\n",
    "counter = 0\n",
    "\n",
    "# Train the model\n",
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_x)\n",
    "        loss = criterion(y_pred.squeeze(), batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    # Early stopping based on validation loss\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = model(X_test_tensor)\n",
    "        val_loss = criterion(val_pred.squeeze(), y_test_tensor)\n",
    "        if val_loss < min_val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            counter = 0  # reset counter\n",
    "        else:\n",
    "            counter += 1  # increment counter\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {epoch_loss/len(train_loader):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_test_pred = model(X_test_tensor).cpu().numpy()\n",
    "    mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a767e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"df.csv\")\n",
    "df.set_index('datetime', inplace=True)\n",
    "# For DataFrame\n",
    "df = df.astype(float)\n",
    "\n",
    "# Sort the DataFrame by datetime\n",
    "df.sort_index(inplace=True)\n",
    "\n",
    "X = df.values\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7216f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save PyTorch model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# Save Scikit-learn scaler\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3c49a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model\n",
    "model_loaded = DNN(input_dim)\n",
    "model_loaded.load_state_dict(model.state_dict())\n",
    "model_loaded.to(device)\n",
    "model_loaded.eval()\n",
    "\n",
    "# Load saved scaler\n",
    "scaler_loaded = scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945baba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2aed03f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Unnamed_0.1_diff_3hr\n- Unnamed_0.1_x\n- Unnamed_0.1_y\n- Unnamed_0_diff_3hr\n- Unnamed_0_x\n- ...\nFeature names seen at fit time, yet now missing:\n- lag_mwh_1\n- lag_mwh_10\n- lag_mwh_11\n- lag_mwh_12\n- lag_mwh_13\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Scale the features using the loaded scaler\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_new_scaled \u001b[38;5;241m=\u001b[39m \u001b[43mscaler_loaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Convert to PyTorch tensor\u001b[39;00m\n\u001b[1;32m      5\u001b[0m X_new_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(X_new_scaled)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:1594\u001b[0m, in \u001b[0;36mRobustScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Center and scale the data.\u001b[39;00m\n\u001b[1;32m   1582\u001b[0m \n\u001b[1;32m   1583\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1591\u001b[0m \u001b[38;5;124;03m    Transformed array.\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1593\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m-> 1594\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_scaling:\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/sklearn/base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    516\u001b[0m ):\n\u001b[1;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    585\u001b[0m         )\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/sklearn/base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    502\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Unnamed_0.1_diff_3hr\n- Unnamed_0.1_x\n- Unnamed_0.1_y\n- Unnamed_0_diff_3hr\n- Unnamed_0_x\n- ...\nFeature names seen at fit time, yet now missing:\n- lag_mwh_1\n- lag_mwh_10\n- lag_mwh_11\n- lag_mwh_12\n- lag_mwh_13\n- ...\n"
     ]
    }
   ],
   "source": [
    "# Scale the features using the loaded scaler\n",
    "X_new_scaled = scaler_loaded.transform(df)\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "X_new_tensor = torch.FloatTensor(X_new_scaled).to(device)\n",
    "\n",
    "# Make predictions using the loaded model\n",
    "with torch.no_grad():\n",
    "    y_pred2 = model_loaded(X_new_tensor).cpu().numpy()\n",
    "\n",
    "# You can add these predictions back to your DataFrame if you like\n",
    "df['Predictions'] = y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "617d1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing joblib for saving models\n",
    "\n",
    "import joblib\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364efb5",
   "metadata": {},
   "source": [
    "# STOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d1074",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9988c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96907f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lightgbm as lgb\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# params = {\n",
    "#     'objective': 'regression',\n",
    "#     'metric': 'mae',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'device': 'gpu',\n",
    "#     'random_state': 42,\n",
    "#     'gpu_platform_id' : 0,\n",
    "#     'gpu_device_id': 0\n",
    "# }\n",
    "\n",
    "# # Create LightGBM data containers\n",
    "# train_data = lgb.Dataset(X_train, label=y_train)\n",
    "# test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "\n",
    "\n",
    "\n",
    "# # Train the model\n",
    "# num_round = 50\n",
    "# bst = lgb.train(params, train_data, num_round, valid_sets=[test_data])\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = bst.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# rmse = np.sqrt(mse)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# print(f\"RMSE: {rmse}\")\n",
    "# print(f\"MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd0f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize JavaScript for SHAP plots\n",
    "shap.initjs()\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.Explainer(model)\n",
    "\n",
    "# Calculate SHAP values for test data\n",
    "shap_values = explainer(X_test)\n",
    "\n",
    "# Plot SHAP summary\n",
    "shap.summary_plot(shap_values, X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be40823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_tensor[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
